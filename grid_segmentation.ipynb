{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ae import AutoEncoder\n",
    "import torch\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_as_np(image_path):\n",
    "    return np.asarray(Image.open(image_path).convert('RGB'), dtype=np.uint8)\n",
    "\n",
    "def store_image_from_np(image_path,data,format='RGB'):\n",
    "    img = Image.fromarray(data, format)\n",
    "    img.save(image_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image,tile_size,pad_type='reflect'):\n",
    "    img_height,img_width = image.shape[:2]\n",
    "\n",
    "    # Pads the image so it can be chunked down to a grid even if the size of the image is not\n",
    "    # divisible by the chunk size\n",
    "    v_pad = (0,tile_size - (img_height % tile_size)) if img_height % tile_size != 0 else (0,0)\n",
    "    h_pad = (0,tile_size - (img_width % tile_size)) if img_width % tile_size != 0 else (0,0)\n",
    "        \n",
    "    image = np.pad(image, (v_pad,h_pad,(0,0)), pad_type)\n",
    "\n",
    "    img_height , img_width, channels = image.shape\n",
    "\n",
    "    tiled_array =  image.reshape(img_height // tile_size,\n",
    "                                 tile_size,\n",
    "                                 img_width // tile_size,\n",
    "                                 tile_size,\n",
    "                                 channels)\n",
    "\n",
    "    tiled_array = tiled_array.swapaxes(1,2)\n",
    "\n",
    "    return np.concatenate(tiled_array,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_image(tile_array,image_size):\n",
    "    img_height, img_width, channels = image_size\n",
    "    \n",
    "    tile_size = tile_array.shape[1]\n",
    "    tile_rows = int(np.ceil(img_height/tile_size))\n",
    "    tile_cols = int(np.ceil(img_width/tile_size))\n",
    "\n",
    "    tile_array = tile_array.reshape(tile_rows,\n",
    "                                    tile_cols,\n",
    "                                    tile_size,\n",
    "                                    tile_size,\n",
    "                                    channels)\n",
    "    #print(\"Rows:\",chunk_rows,\"Cols:\",chunk_cols, \"New shape:\",new_shape)\n",
    "    \n",
    "    tile_array = np.concatenate(tile_array,axis=1)\n",
    "    tile_array = np.concatenate(tile_array,axis=1)\n",
    "\n",
    "    return tile_array[:img_height,:img_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoEncoder.load_autoencoder(model_path)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def apply_compress_function(tile_tensor, model_path):\n",
    "    model = get_model(model_path)\n",
    "    return model.encode(tile_tensor)\n",
    "\n",
    "def apply_decompression_function(encoded_tile_tensor,model_path) :\n",
    "    model = get_model(model_path)\n",
    "    return model.decode(encoded_tile_tensor)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor(tile_list_array):\n",
    "    tile_tensor = torch.from_numpy(tile_list_array)\n",
    "    print(tile_tensor.reshape(-1,3*8*8))\n",
    "\n",
    "    return tile_tensor\n",
    "\n",
    "def retrieve_array(decoded_tile_tensor):\n",
    "    return decoded_tile_tensor.detach().cpu().view(-1,3,8,8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  28 207  18 164   4 205   0]\n",
      "   [197  21 214   0 198   0 222   0]\n",
      "   [204  62 102   0 150  26 199  35]\n",
      "   [204 150   0 128  35 132 190   3]\n",
      "   [ 34 147  41  65 135  76 160 163]\n",
      "   [241 156  67 151  17  32  50  58]\n",
      "   [221  42  22  17  55  13  58  48]\n",
      "   [ 77  53  20  84   4  43  56 101]]\n",
      "\n",
      "  [[ 38  18 216  39 193  30 219   1]\n",
      "   [177   9 224  22 227  16 233   5]\n",
      "   [180  49 107   6 175  46 204  34]\n",
      "   [178 133   0 143  54 147 191   0]\n",
      "   [  4 126  40  74 148  85 156 151]\n",
      "   [209 131  62 156  27  35  40  40]\n",
      "   [185  13  13  18  58  13  40  24]\n",
      "   [ 38  23   9  84   6  39  37  73]]\n",
      "\n",
      "  [[ 53  29 221  40 191  29 222   7]\n",
      "   [189  19 226  20 223  13 235   9]\n",
      "   [194  59 111   6 172  45 208  40]\n",
      "   [189 141   2 140  50 144 193   2]\n",
      "   [ 12 131  38  69 141  80 155 153]\n",
      "   [214 134  58 149  18  28  38  40]\n",
      "   [189  15   8  10  49   5  38  24]\n",
      "   [ 41  23   3  74   0  30  33  72]]]]\n",
      "tensor([[ 59,  28, 207,  18, 164,   4, 205,   0, 197,  21, 214,   0, 198,   0,\n",
      "         222,   0, 204,  62, 102,   0, 150,  26, 199,  35, 204, 150,   0, 128,\n",
      "          35, 132, 190,   3,  34, 147,  41,  65, 135,  76, 160, 163, 241, 156,\n",
      "          67, 151,  17,  32,  50,  58, 221,  42,  22,  17,  55,  13,  58,  48,\n",
      "          77,  53,  20,  84,   4,  43,  56, 101,  38,  18, 216,  39, 193,  30,\n",
      "         219,   1, 177,   9, 224,  22, 227,  16, 233,   5, 180,  49, 107,   6,\n",
      "         175,  46, 204,  34, 178, 133,   0, 143,  54, 147, 191,   0,   4, 126,\n",
      "          40,  74, 148,  85, 156, 151, 209, 131,  62, 156,  27,  35,  40,  40,\n",
      "         185,  13,  13,  18,  58,  13,  40,  24,  38,  23,   9,  84,   6,  39,\n",
      "          37,  73,  53,  29, 221,  40, 191,  29, 222,   7, 189,  19, 226,  20,\n",
      "         223,  13, 235,   9, 194,  59, 111,   6, 172,  45, 208,  40, 189, 141,\n",
      "           2, 140,  50, 144, 193,   2,  12, 131,  38,  69, 141,  80, 155, 153,\n",
      "         214, 134,  58, 149,  18,  28,  38,  40, 189,  15,   8,  10,  49,   5,\n",
      "          38,  24,  41,  23,   3,  74,   0,  30,  33,  72]], dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12788/3424276183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtile_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpad_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reflect'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mc_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_compress_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_used_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdc_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_decompression_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_used_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12788/1988280429.py\u001b[0m in \u001b[0;36mapply_compress_function\u001b[1;34m(tile_list_array, model_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtile_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtile_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_decompression_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_tile_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nacho\\Desktop\\TFG\\ae.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Byte"
     ]
    }
   ],
   "source": [
    "wd_path = os.path.abspath(os.getcwd())\n",
    "models_path = os.path.join(wd_path, \"models\")\n",
    "model_used_path = os.path.join(models_path, \"ae_0.pt\")\n",
    "image_path = os.path.join(wd_path,\"images\",\"val_0_0.jpeg\")\n",
    "image_path_out = os.path.join(wd_path,\"images\",\"val_0_0_out.jpeg\")\n",
    "\n",
    "test_image= load_image_as_np(image_path)\n",
    "tile_list = segment_image(test_image,tile_size=8,pad_type='reflect')\n",
    "\n",
    "c_image = apply_compress_function(tile_list,model_used_path)\n",
    "dc_image = apply_decompression_function(c_image,model_used_path)\n",
    "\n",
    "end_image = rebuild_image(dc_image,test_image.shape)\n",
    "plt.imshow(end_image.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: (900, 1200, 3)\n",
      "Number of 8x8 tiles: 16950\n",
      "(16950, 3, 8, 8)\n",
      "torch.Size([16950, 3, 8, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12788/2289363694.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of {tile_size}x{tile_size} tiles:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtile_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mc_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_compress_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_used_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdc_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_decompression_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_used_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12788/1204020669.py\u001b[0m in \u001b[0;36mapply_compress_function\u001b[1;34m(tile_list_array, model_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtile_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtile_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtile_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_decompression_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_tile_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nacho\\Desktop\\TFG\\ae.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "wd_path = os.path.abspath(os.getcwd())\n",
    "models_path = os.path.join(wd_path, \"models\")\n",
    "model_used_path = os.path.join(models_path, \"ae_0.pt\")\n",
    "image_path = os.path.join(wd_path,\"images\",\"tenemos.png\")\n",
    "image_path_out = os.path.join(wd_path,\"images\",\"tenemos_out.png\")\n",
    "tile_size= 8\n",
    "\n",
    "image = load_image_as_np(image_path)\n",
    "\n",
    "print(\"Original size:\",image.shape)\n",
    "tile_list = segment_image(image,tile_size,pad_type='reflect')\n",
    "print(f\"Number of {tile_size}x{tile_size} tiles:\",tile_list.shape[0])\n",
    "\n",
    "c_image = apply_compress_function(tile_list,model_used_path)\n",
    "dc_image = apply_decompression_function(c_image,model_used_path)\n",
    "\n",
    "end_image = rebuild_image(dc_image,image.shape)\n",
    "#print(\"Original and end images are equal:\",(end_image==image).all())\n",
    "#print(\"With equal shape:\",(end_image.shape==image.shape))\n",
    "\n",
    "img = store_image_from_np(image_path_out,end_image,format='RGB')\n",
    "\n",
    "plt.imshow(end_image.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80eecae6fe367bf31bafaafee0935a4935edb539e731c9082f4e2c31e5b4f550"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
