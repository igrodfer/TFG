{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, features\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ae import AutoEncoder\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/introduction')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using the device\",device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def take_random_tile(img_raw,tile_size=8,sample_shape_range=None):\n",
    "    channels, width,height=list(img_raw.shape) #(3,width,height)\n",
    "\n",
    "    if sample_shape_range != None:\n",
    "        min_size, max_size = sample_shape_range\n",
    "\n",
    "        tile_size = randint(min_size,max_size)\n",
    "\n",
    "        if tile_size > width or tile_size > height: #correct for sample sizes bigger than the image\n",
    "            tile_size = min(height,width)\n",
    "    \n",
    "    top  = randint(0,width-tile_size)\n",
    "    left = randint(0,height-tile_size)\n",
    "\n",
    "    tile_tensor = img_raw[:,top:top+tile_size,left:left+tile_size] #tile\n",
    "    #print(list(tile_tensor.shape))\n",
    "\n",
    "    if sample_shape_range != None:\n",
    "        tile_tensor = F.interpolate(tile_tensor,size=(channels,tile_size,tile_size))\n",
    "    return tile_tensor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def get_tile_batch(image_list, batch_size=1000, tile_size=8, sample_shape_range=None):\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    while True:\n",
    "        tile_list = [] #initialize batch tensor\n",
    "        for i in range(batch_size):\n",
    "            next_image,=sample(image_list,k=1)\n",
    "            image_tensor = convert_tensor(Image.open(next_image).convert('RGB'))\n",
    "            tile = take_random_tile(image_tensor,tile_size,sample_shape_range)\n",
    "            #print(tile.shape)\n",
    "            tile_list.append(tile)\n",
    "\n",
    "        batch = torch.stack(tile_list)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "wd_path = os.path.abspath(os.getcwd())\n",
    "root_path = os.path.join(wd_path, \"datasets\", 'ImageNet','train')\n",
    "\n",
    "\n",
    "image_path_list = []\n",
    "for d in listdir(root_path):\n",
    "    #d = n016...\n",
    "    class_path = join(root_path,d,\"images\")\n",
    "    for i in listdir(class_path):\n",
    "        #i = n016..._n.JPEG\n",
    "        image_path_list.append(join(class_path,i))\n",
    "\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=8)\n",
    "sample_images = next(batch_maker)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(sample_images))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(epoch_size, train_loader,optimizer,model,criterion,max_epochs):\n",
    "    training_loss_history= []\n",
    "    loss = 0\n",
    "    min_loss = 1\n",
    "    for epoch_number,tiles in enumerate(train_loader):\n",
    "\n",
    "        # reshape mini-batch data to [N, 3*8*8] matrix\n",
    "        # load it to the active device\n",
    "        tiles = tiles.to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(tiles)                 # compute reconstructions\n",
    "        train_loss = criterion(outputs, tiles.view(-1, 3*8*8)) # compute training reconstruction loss\n",
    "        train_loss.backward()                  # compute accumulated gradients\n",
    "        optimizer.step()                       # perform parameter update based on current gradients\n",
    "        loss += train_loss.item()              # add the mini-batch training loss to epoch loss\n",
    "        \n",
    "        if epoch_number%epoch_size == epoch_size-1:\n",
    "            # compute the epoch training loss\n",
    "            loss = loss / epoch_size\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_params = model.state_dict()\n",
    "            # display the epoch training loss\n",
    "            print(f\"epoch : {(epoch_number+1)/epoch_size}, loss = {loss:.6f}\")\n",
    "            training_loss_history.append(loss)\n",
    "            loss = 0\n",
    "            if(epoch_number >= max_epochs):\n",
    "                return best_params\n",
    "                \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AutoEncoder()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=1000)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1.0, loss = 0.011681\n",
      "epoch : 2.0, loss = 0.011418\n",
      "epoch : 3.0, loss = 0.011560\n",
      "epoch : 4.0, loss = 0.011693\n",
      "epoch : 5.0, loss = 0.011612\n",
      "epoch : 6.0, loss = 0.011717\n",
      "epoch : 7.0, loss = 0.011680\n",
      "epoch : 8.0, loss = 0.011654\n",
      "epoch : 9.0, loss = 0.011917\n",
      "epoch : 10.0, loss = 0.011740\n",
      "epoch : 11.0, loss = 0.011801\n",
      "epoch : 12.0, loss = 0.011772\n",
      "epoch : 13.0, loss = 0.011870\n",
      "epoch : 14.0, loss = 0.011950\n",
      "epoch : 15.0, loss = 0.011910\n",
      "epoch : 16.0, loss = 0.011709\n",
      "epoch : 17.0, loss = 0.011675\n",
      "epoch : 18.0, loss = 0.011615\n",
      "epoch : 19.0, loss = 0.011796\n",
      "epoch : 20.0, loss = 0.011859\n",
      "epoch : 21.0, loss = 0.011748\n",
      "epoch : 22.0, loss = 0.011782\n",
      "epoch : 23.0, loss = 0.011832\n",
      "epoch : 24.0, loss = 0.011701\n",
      "epoch : 25.0, loss = 0.011619\n",
      "epoch : 26.0, loss = 0.011828\n",
      "epoch : 27.0, loss = 0.011850\n",
      "epoch : 28.0, loss = 0.011738\n",
      "epoch : 29.0, loss = 0.011484\n",
      "epoch : 30.0, loss = 0.011770\n",
      "epoch : 31.0, loss = 0.011964\n",
      "epoch : 32.0, loss = 0.011866\n",
      "epoch : 33.0, loss = 0.011643\n",
      "epoch : 34.0, loss = 0.011851\n",
      "epoch : 35.0, loss = 0.011694\n",
      "epoch : 36.0, loss = 0.011750\n",
      "epoch : 37.0, loss = 0.011685\n",
      "epoch : 38.0, loss = 0.011669\n",
      "epoch : 39.0, loss = 0.011621\n",
      "epoch : 40.0, loss = 0.012064\n",
      "epoch : 41.0, loss = 0.011769\n",
      "epoch : 42.0, loss = 0.011722\n",
      "epoch : 43.0, loss = 0.011794\n",
      "epoch : 44.0, loss = 0.011706\n",
      "epoch : 45.0, loss = 0.011724\n",
      "epoch : 46.0, loss = 0.011680\n",
      "epoch : 47.0, loss = 0.011608\n",
      "epoch : 48.0, loss = 0.011850\n",
      "epoch : 49.0, loss = 0.011564\n",
      "epoch : 50.0, loss = 0.011836\n",
      "epoch : 51.0, loss = 0.011849\n",
      "epoch : 52.0, loss = 0.011700\n",
      "epoch : 53.0, loss = 0.011688\n",
      "epoch : 54.0, loss = 0.011717\n",
      "epoch : 55.0, loss = 0.011937\n",
      "epoch : 56.0, loss = 0.011704\n",
      "epoch : 57.0, loss = 0.011835\n",
      "epoch : 58.0, loss = 0.011878\n",
      "epoch : 59.0, loss = 0.011666\n",
      "epoch : 60.0, loss = 0.011572\n",
      "epoch : 61.0, loss = 0.011713\n",
      "epoch : 62.0, loss = 0.011587\n",
      "epoch : 63.0, loss = 0.011651\n",
      "epoch : 64.0, loss = 0.011674\n",
      "epoch : 65.0, loss = 0.011720\n",
      "epoch : 66.0, loss = 0.011676\n",
      "epoch : 67.0, loss = 0.011885\n",
      "epoch : 68.0, loss = 0.011679\n",
      "epoch : 69.0, loss = 0.011890\n",
      "epoch : 70.0, loss = 0.011785\n",
      "epoch : 71.0, loss = 0.011685\n",
      "epoch : 72.0, loss = 0.011679\n",
      "epoch : 73.0, loss = 0.011934\n",
      "epoch : 74.0, loss = 0.011685\n",
      "epoch : 75.0, loss = 0.011811\n",
      "epoch : 76.0, loss = 0.011678\n",
      "epoch : 77.0, loss = 0.011741\n",
      "epoch : 78.0, loss = 0.011773\n",
      "epoch : 79.0, loss = 0.011573\n",
      "epoch : 80.0, loss = 0.011912\n",
      "epoch : 81.0, loss = 0.011730\n",
      "epoch : 82.0, loss = 0.011603\n",
      "epoch : 83.0, loss = 0.011873\n",
      "epoch : 84.0, loss = 0.011530\n",
      "epoch : 85.0, loss = 0.011575\n",
      "epoch : 86.0, loss = 0.011711\n",
      "epoch : 87.0, loss = 0.011625\n",
      "epoch : 88.0, loss = 0.011739\n",
      "epoch : 89.0, loss = 0.011783\n",
      "epoch : 90.0, loss = 0.011741\n",
      "epoch : 91.0, loss = 0.011791\n",
      "epoch : 92.0, loss = 0.011969\n",
      "epoch : 93.0, loss = 0.011719\n",
      "epoch : 94.0, loss = 0.011726\n",
      "epoch : 95.0, loss = 0.011794\n",
      "epoch : 96.0, loss = 0.011848\n",
      "epoch : 97.0, loss = 0.011657\n",
      "epoch : 98.0, loss = 0.011754\n",
      "epoch : 99.0, loss = 0.011845\n",
      "epoch : 100.0, loss = 0.011833\n",
      "epoch : 101.0, loss = 0.011784\n",
      "epoch : 102.0, loss = 0.011603\n",
      "epoch : 103.0, loss = 0.011536\n",
      "epoch : 104.0, loss = 0.011887\n",
      "epoch : 105.0, loss = 0.011845\n",
      "epoch : 106.0, loss = 0.011776\n",
      "epoch : 107.0, loss = 0.011776\n",
      "epoch : 108.0, loss = 0.011999\n",
      "epoch : 109.0, loss = 0.011510\n",
      "epoch : 110.0, loss = 0.011630\n",
      "epoch : 111.0, loss = 0.011795\n",
      "epoch : 112.0, loss = 0.011968\n",
      "epoch : 113.0, loss = 0.011491\n",
      "epoch : 114.0, loss = 0.011619\n",
      "epoch : 115.0, loss = 0.011550\n",
      "epoch : 116.0, loss = 0.011660\n",
      "epoch : 117.0, loss = 0.011708\n",
      "epoch : 118.0, loss = 0.011806\n",
      "epoch : 119.0, loss = 0.011677\n",
      "epoch : 120.0, loss = 0.012073\n",
      "epoch : 121.0, loss = 0.011651\n",
      "epoch : 122.0, loss = 0.011592\n",
      "epoch : 123.0, loss = 0.011891\n",
      "epoch : 124.0, loss = 0.011580\n",
      "epoch : 125.0, loss = 0.011781\n",
      "epoch : 126.0, loss = 0.011555\n",
      "epoch : 127.0, loss = 0.011903\n",
      "epoch : 128.0, loss = 0.011724\n",
      "epoch : 129.0, loss = 0.011646\n",
      "epoch : 130.0, loss = 0.011816\n",
      "epoch : 131.0, loss = 0.011666\n",
      "epoch : 132.0, loss = 0.011824\n",
      "epoch : 133.0, loss = 0.011633\n",
      "epoch : 134.0, loss = 0.011751\n",
      "epoch : 135.0, loss = 0.011791\n",
      "epoch : 136.0, loss = 0.011919\n",
      "epoch : 137.0, loss = 0.011838\n",
      "epoch : 138.0, loss = 0.011990\n",
      "epoch : 139.0, loss = 0.011875\n",
      "epoch : 140.0, loss = 0.011889\n",
      "epoch : 141.0, loss = 0.011524\n",
      "epoch : 142.0, loss = 0.011746\n",
      "epoch : 143.0, loss = 0.011656\n",
      "epoch : 144.0, loss = 0.011832\n",
      "epoch : 145.0, loss = 0.011666\n",
      "epoch : 146.0, loss = 0.011964\n",
      "epoch : 147.0, loss = 0.011820\n",
      "epoch : 148.0, loss = 0.011892\n",
      "epoch : 149.0, loss = 0.011816\n",
      "epoch : 150.0, loss = 0.011683\n",
      "epoch : 151.0, loss = 0.011725\n",
      "epoch : 152.0, loss = 0.011815\n",
      "epoch : 153.0, loss = 0.011604\n",
      "epoch : 154.0, loss = 0.011559\n",
      "epoch : 155.0, loss = 0.011914\n",
      "epoch : 156.0, loss = 0.011531\n",
      "epoch : 157.0, loss = 0.012109\n",
      "epoch : 158.0, loss = 0.011589\n",
      "epoch : 159.0, loss = 0.011901\n",
      "epoch : 160.0, loss = 0.012050\n",
      "epoch : 161.0, loss = 0.011921\n",
      "epoch : 162.0, loss = 0.011709\n",
      "epoch : 163.0, loss = 0.011781\n",
      "epoch : 164.0, loss = 0.011668\n",
      "epoch : 165.0, loss = 0.011779\n",
      "epoch : 166.0, loss = 0.011802\n",
      "epoch : 167.0, loss = 0.011719\n",
      "epoch : 168.0, loss = 0.011850\n",
      "epoch : 169.0, loss = 0.011651\n",
      "epoch : 170.0, loss = 0.011871\n",
      "epoch : 171.0, loss = 0.011499\n",
      "epoch : 172.0, loss = 0.011811\n",
      "epoch : 173.0, loss = 0.011920\n",
      "epoch : 174.0, loss = 0.011832\n",
      "epoch : 175.0, loss = 0.011909\n",
      "epoch : 176.0, loss = 0.011723\n",
      "epoch : 177.0, loss = 0.011806\n",
      "epoch : 178.0, loss = 0.011789\n",
      "epoch : 179.0, loss = 0.012025\n",
      "epoch : 180.0, loss = 0.011845\n",
      "epoch : 181.0, loss = 0.011806\n",
      "epoch : 182.0, loss = 0.011621\n",
      "epoch : 183.0, loss = 0.011683\n",
      "epoch : 184.0, loss = 0.011858\n",
      "epoch : 185.0, loss = 0.011891\n",
      "epoch : 186.0, loss = 0.011567\n",
      "epoch : 187.0, loss = 0.011770\n",
      "epoch : 188.0, loss = 0.011604\n",
      "epoch : 189.0, loss = 0.011634\n",
      "epoch : 190.0, loss = 0.011551\n",
      "epoch : 191.0, loss = 0.011955\n",
      "epoch : 192.0, loss = 0.011846\n",
      "epoch : 193.0, loss = 0.011633\n",
      "epoch : 194.0, loss = 0.011846\n",
      "epoch : 195.0, loss = 0.011816\n",
      "epoch : 196.0, loss = 0.011747\n",
      "epoch : 197.0, loss = 0.011783\n",
      "epoch : 198.0, loss = 0.011728\n",
      "epoch : 199.0, loss = 0.011676\n",
      "epoch : 200.0, loss = 0.011859\n",
      "epoch : 201.0, loss = 0.011679\n",
      "epoch : 202.0, loss = 0.011766\n",
      "epoch : 203.0, loss = 0.011813\n",
      "epoch : 204.0, loss = 0.012016\n",
      "epoch : 205.0, loss = 0.011459\n",
      "epoch : 206.0, loss = 0.011776\n",
      "epoch : 207.0, loss = 0.011760\n",
      "epoch : 208.0, loss = 0.011779\n",
      "epoch : 209.0, loss = 0.011752\n",
      "epoch : 210.0, loss = 0.011696\n",
      "epoch : 211.0, loss = 0.011668\n",
      "epoch : 212.0, loss = 0.011704\n",
      "epoch : 213.0, loss = 0.011804\n",
      "epoch : 214.0, loss = 0.011744\n",
      "epoch : 215.0, loss = 0.011873\n",
      "epoch : 216.0, loss = 0.011587\n",
      "epoch : 217.0, loss = 0.011648\n",
      "epoch : 218.0, loss = 0.011800\n",
      "epoch : 219.0, loss = 0.011545\n",
      "epoch : 220.0, loss = 0.011474\n",
      "epoch : 221.0, loss = 0.011664\n",
      "epoch : 222.0, loss = 0.011790\n",
      "epoch : 223.0, loss = 0.011527\n",
      "epoch : 224.0, loss = 0.011814\n",
      "epoch : 225.0, loss = 0.011464\n",
      "epoch : 226.0, loss = 0.011755\n",
      "epoch : 227.0, loss = 0.011838\n",
      "epoch : 228.0, loss = 0.011867\n",
      "epoch : 229.0, loss = 0.011669\n",
      "epoch : 230.0, loss = 0.011606\n",
      "epoch : 231.0, loss = 0.011611\n",
      "epoch : 232.0, loss = 0.011687\n",
      "epoch : 233.0, loss = 0.011760\n",
      "epoch : 234.0, loss = 0.011458\n",
      "epoch : 235.0, loss = 0.011817\n",
      "epoch : 236.0, loss = 0.011484\n",
      "epoch : 237.0, loss = 0.011975\n",
      "epoch : 238.0, loss = 0.011818\n",
      "epoch : 239.0, loss = 0.011430\n",
      "epoch : 240.0, loss = 0.011941\n",
      "epoch : 241.0, loss = 0.011773\n",
      "epoch : 242.0, loss = 0.011761\n",
      "epoch : 243.0, loss = 0.011806\n",
      "epoch : 244.0, loss = 0.011818\n",
      "epoch : 245.0, loss = 0.011641\n",
      "epoch : 246.0, loss = 0.011701\n",
      "epoch : 247.0, loss = 0.011903\n",
      "epoch : 248.0, loss = 0.011724\n",
      "epoch : 249.0, loss = 0.011865\n",
      "epoch : 250.0, loss = 0.011777\n",
      "epoch : 251.0, loss = 0.011730\n",
      "epoch : 252.0, loss = 0.011789\n",
      "epoch : 253.0, loss = 0.012015\n",
      "epoch : 254.0, loss = 0.011897\n",
      "epoch : 255.0, loss = 0.011683\n",
      "epoch : 256.0, loss = 0.012074\n",
      "epoch : 257.0, loss = 0.011790\n",
      "epoch : 258.0, loss = 0.011784\n",
      "epoch : 259.0, loss = 0.011692\n",
      "epoch : 260.0, loss = 0.011872\n",
      "epoch : 261.0, loss = 0.011535\n",
      "epoch : 262.0, loss = 0.011659\n",
      "epoch : 263.0, loss = 0.011911\n",
      "epoch : 264.0, loss = 0.011971\n",
      "epoch : 265.0, loss = 0.011747\n",
      "epoch : 266.0, loss = 0.011653\n",
      "epoch : 267.0, loss = 0.011867\n",
      "epoch : 268.0, loss = 0.011570\n",
      "epoch : 269.0, loss = 0.011876\n",
      "epoch : 270.0, loss = 0.011737\n",
      "epoch : 271.0, loss = 0.011797\n",
      "epoch : 272.0, loss = 0.011448\n",
      "epoch : 273.0, loss = 0.011821\n",
      "epoch : 274.0, loss = 0.011709\n",
      "epoch : 275.0, loss = 0.012005\n",
      "epoch : 276.0, loss = 0.011910\n",
      "epoch : 277.0, loss = 0.011672\n",
      "epoch : 278.0, loss = 0.011726\n",
      "epoch : 279.0, loss = 0.011663\n",
      "epoch : 280.0, loss = 0.011749\n",
      "epoch : 281.0, loss = 0.011618\n",
      "epoch : 282.0, loss = 0.011658\n",
      "epoch : 283.0, loss = 0.012030\n",
      "epoch : 284.0, loss = 0.011559\n",
      "epoch : 285.0, loss = 0.011734\n",
      "epoch : 286.0, loss = 0.011978\n",
      "epoch : 287.0, loss = 0.011805\n",
      "epoch : 288.0, loss = 0.011977\n",
      "epoch : 289.0, loss = 0.011862\n",
      "epoch : 290.0, loss = 0.011629\n",
      "epoch : 291.0, loss = 0.011900\n",
      "epoch : 292.0, loss = 0.011736\n",
      "epoch : 293.0, loss = 0.011586\n",
      "epoch : 294.0, loss = 0.011710\n",
      "epoch : 295.0, loss = 0.011390\n",
      "epoch : 296.0, loss = 0.011663\n",
      "epoch : 297.0, loss = 0.011751\n",
      "epoch : 298.0, loss = 0.011706\n",
      "epoch : 299.0, loss = 0.011749\n",
      "epoch : 300.0, loss = 0.011719\n",
      "epoch : 301.0, loss = 0.011679\n",
      "epoch : 302.0, loss = 0.011919\n",
      "epoch : 303.0, loss = 0.011707\n",
      "epoch : 304.0, loss = 0.011589\n",
      "epoch : 305.0, loss = 0.011772\n",
      "epoch : 306.0, loss = 0.011676\n",
      "epoch : 307.0, loss = 0.011757\n",
      "epoch : 308.0, loss = 0.012000\n",
      "epoch : 309.0, loss = 0.011688\n",
      "epoch : 310.0, loss = 0.011695\n",
      "epoch : 311.0, loss = 0.011581\n",
      "epoch : 312.0, loss = 0.011755\n",
      "epoch : 313.0, loss = 0.011822\n",
      "epoch : 314.0, loss = 0.011612\n",
      "epoch : 315.0, loss = 0.011794\n",
      "epoch : 316.0, loss = 0.011636\n",
      "epoch : 317.0, loss = 0.011790\n",
      "epoch : 318.0, loss = 0.011839\n",
      "epoch : 319.0, loss = 0.011573\n",
      "epoch : 320.0, loss = 0.011653\n",
      "epoch : 321.0, loss = 0.011622\n",
      "epoch : 322.0, loss = 0.011870\n",
      "epoch : 323.0, loss = 0.011720\n",
      "epoch : 324.0, loss = 0.011887\n",
      "epoch : 325.0, loss = 0.011858\n",
      "epoch : 326.0, loss = 0.011541\n",
      "epoch : 327.0, loss = 0.011884\n",
      "epoch : 328.0, loss = 0.011719\n",
      "epoch : 329.0, loss = 0.011912\n",
      "epoch : 330.0, loss = 0.011604\n",
      "epoch : 331.0, loss = 0.011936\n",
      "epoch : 332.0, loss = 0.011675\n",
      "epoch : 333.0, loss = 0.011763\n",
      "epoch : 334.0, loss = 0.011719\n",
      "epoch : 335.0, loss = 0.011860\n",
      "epoch : 336.0, loss = 0.011838\n",
      "epoch : 337.0, loss = 0.011803\n",
      "epoch : 338.0, loss = 0.011852\n",
      "epoch : 339.0, loss = 0.011620\n",
      "epoch : 340.0, loss = 0.011531\n",
      "epoch : 341.0, loss = 0.011717\n",
      "epoch : 342.0, loss = 0.011645\n",
      "epoch : 343.0, loss = 0.011889\n",
      "epoch : 344.0, loss = 0.011637\n",
      "epoch : 345.0, loss = 0.011739\n",
      "epoch : 346.0, loss = 0.011805\n",
      "epoch : 347.0, loss = 0.011744\n",
      "epoch : 348.0, loss = 0.011715\n",
      "epoch : 349.0, loss = 0.012001\n",
      "epoch : 350.0, loss = 0.011760\n",
      "epoch : 351.0, loss = 0.011727\n",
      "epoch : 352.0, loss = 0.011635\n",
      "epoch : 353.0, loss = 0.011704\n",
      "epoch : 354.0, loss = 0.011819\n",
      "epoch : 355.0, loss = 0.011870\n",
      "epoch : 356.0, loss = 0.011758\n",
      "epoch : 357.0, loss = 0.011887\n",
      "epoch : 358.0, loss = 0.011842\n",
      "epoch : 359.0, loss = 0.011864\n",
      "epoch : 360.0, loss = 0.011660\n",
      "epoch : 361.0, loss = 0.011707\n",
      "epoch : 362.0, loss = 0.011862\n",
      "epoch : 363.0, loss = 0.011774\n",
      "epoch : 364.0, loss = 0.011847\n",
      "epoch : 365.0, loss = 0.011631\n",
      "epoch : 366.0, loss = 0.011887\n",
      "epoch : 367.0, loss = 0.011669\n",
      "epoch : 368.0, loss = 0.011915\n",
      "epoch : 369.0, loss = 0.011750\n",
      "epoch : 370.0, loss = 0.011695\n",
      "epoch : 371.0, loss = 0.011636\n",
      "epoch : 372.0, loss = 0.011686\n",
      "epoch : 373.0, loss = 0.011607\n",
      "epoch : 374.0, loss = 0.011712\n",
      "epoch : 375.0, loss = 0.011834\n",
      "epoch : 376.0, loss = 0.011852\n",
      "epoch : 377.0, loss = 0.011813\n",
      "epoch : 378.0, loss = 0.011729\n",
      "epoch : 379.0, loss = 0.011848\n",
      "epoch : 380.0, loss = 0.011882\n",
      "epoch : 381.0, loss = 0.011913\n",
      "epoch : 382.0, loss = 0.011786\n",
      "epoch : 383.0, loss = 0.011794\n",
      "epoch : 384.0, loss = 0.011560\n",
      "epoch : 385.0, loss = 0.011764\n",
      "epoch : 386.0, loss = 0.011543\n",
      "epoch : 387.0, loss = 0.011769\n",
      "epoch : 388.0, loss = 0.011669\n",
      "epoch : 389.0, loss = 0.011802\n",
      "epoch : 390.0, loss = 0.011882\n",
      "epoch : 391.0, loss = 0.012040\n",
      "epoch : 392.0, loss = 0.011582\n",
      "epoch : 393.0, loss = 0.011616\n",
      "epoch : 394.0, loss = 0.011752\n",
      "epoch : 395.0, loss = 0.011691\n",
      "epoch : 396.0, loss = 0.011796\n",
      "epoch : 397.0, loss = 0.011808\n",
      "epoch : 398.0, loss = 0.011813\n",
      "epoch : 399.0, loss = 0.011627\n",
      "epoch : 400.0, loss = 0.011648\n",
      "epoch : 401.0, loss = 0.012077\n",
      "epoch : 402.0, loss = 0.011528\n",
      "epoch : 403.0, loss = 0.011600\n",
      "epoch : 404.0, loss = 0.011802\n",
      "epoch : 405.0, loss = 0.011587\n",
      "epoch : 406.0, loss = 0.011499\n",
      "epoch : 407.0, loss = 0.011768\n",
      "epoch : 408.0, loss = 0.011860\n",
      "epoch : 409.0, loss = 0.011664\n",
      "epoch : 410.0, loss = 0.011891\n",
      "epoch : 411.0, loss = 0.011931\n",
      "epoch : 412.0, loss = 0.011684\n",
      "epoch : 413.0, loss = 0.011793\n",
      "epoch : 414.0, loss = 0.011646\n",
      "epoch : 415.0, loss = 0.011804\n",
      "epoch : 416.0, loss = 0.011876\n",
      "epoch : 417.0, loss = 0.011922\n",
      "epoch : 418.0, loss = 0.011718\n",
      "epoch : 419.0, loss = 0.011857\n",
      "epoch : 420.0, loss = 0.011588\n",
      "epoch : 421.0, loss = 0.011727\n",
      "epoch : 422.0, loss = 0.011465\n",
      "epoch : 423.0, loss = 0.011664\n",
      "epoch : 424.0, loss = 0.011500\n",
      "epoch : 425.0, loss = 0.011957\n",
      "epoch : 426.0, loss = 0.011504\n",
      "epoch : 427.0, loss = 0.011963\n",
      "epoch : 428.0, loss = 0.011700\n",
      "epoch : 429.0, loss = 0.011558\n",
      "epoch : 430.0, loss = 0.011659\n",
      "epoch : 431.0, loss = 0.011571\n",
      "epoch : 432.0, loss = 0.011667\n",
      "epoch : 433.0, loss = 0.011661\n",
      "epoch : 434.0, loss = 0.011679\n",
      "epoch : 435.0, loss = 0.011755\n",
      "epoch : 436.0, loss = 0.011519\n",
      "epoch : 437.0, loss = 0.011554\n",
      "epoch : 438.0, loss = 0.011731\n",
      "epoch : 439.0, loss = 0.011778\n",
      "epoch : 440.0, loss = 0.011675\n",
      "epoch : 441.0, loss = 0.011775\n",
      "epoch : 442.0, loss = 0.011686\n",
      "epoch : 443.0, loss = 0.011652\n",
      "epoch : 444.0, loss = 0.011605\n",
      "epoch : 445.0, loss = 0.011819\n",
      "epoch : 446.0, loss = 0.011600\n",
      "epoch : 447.0, loss = 0.011804\n",
      "epoch : 448.0, loss = 0.011479\n",
      "epoch : 449.0, loss = 0.011685\n",
      "epoch : 450.0, loss = 0.012126\n",
      "epoch : 451.0, loss = 0.011943\n",
      "epoch : 452.0, loss = 0.011695\n",
      "epoch : 453.0, loss = 0.011526\n",
      "epoch : 454.0, loss = 0.011580\n",
      "epoch : 455.0, loss = 0.011729\n",
      "epoch : 456.0, loss = 0.011682\n",
      "epoch : 457.0, loss = 0.011581\n",
      "epoch : 458.0, loss = 0.011723\n",
      "epoch : 459.0, loss = 0.011959\n",
      "epoch : 460.0, loss = 0.011908\n",
      "epoch : 461.0, loss = 0.011769\n",
      "epoch : 462.0, loss = 0.011555\n",
      "epoch : 463.0, loss = 0.011697\n",
      "epoch : 464.0, loss = 0.011891\n",
      "epoch : 465.0, loss = 0.011745\n",
      "epoch : 466.0, loss = 0.011715\n",
      "epoch : 467.0, loss = 0.011910\n",
      "epoch : 468.0, loss = 0.011651\n",
      "epoch : 469.0, loss = 0.011631\n",
      "epoch : 470.0, loss = 0.011774\n",
      "epoch : 471.0, loss = 0.011598\n",
      "epoch : 472.0, loss = 0.011873\n",
      "epoch : 473.0, loss = 0.011830\n",
      "epoch : 474.0, loss = 0.011852\n",
      "epoch : 475.0, loss = 0.011585\n",
      "epoch : 476.0, loss = 0.011800\n",
      "epoch : 477.0, loss = 0.011791\n",
      "epoch : 478.0, loss = 0.011627\n",
      "epoch : 479.0, loss = 0.011518\n",
      "epoch : 480.0, loss = 0.011744\n",
      "epoch : 481.0, loss = 0.011813\n",
      "epoch : 482.0, loss = 0.011848\n",
      "epoch : 483.0, loss = 0.011659\n",
      "epoch : 484.0, loss = 0.011778\n",
      "epoch : 485.0, loss = 0.011676\n",
      "epoch : 486.0, loss = 0.011788\n",
      "epoch : 487.0, loss = 0.011750\n",
      "epoch : 488.0, loss = 0.011957\n",
      "epoch : 489.0, loss = 0.011782\n",
      "epoch : 490.0, loss = 0.011904\n",
      "epoch : 491.0, loss = 0.011655\n",
      "epoch : 492.0, loss = 0.011719\n",
      "epoch : 493.0, loss = 0.011707\n",
      "epoch : 494.0, loss = 0.011916\n",
      "epoch : 495.0, loss = 0.011686\n",
      "epoch : 496.0, loss = 0.011723\n",
      "epoch : 497.0, loss = 0.012013\n",
      "epoch : 498.0, loss = 0.011805\n",
      "epoch : 499.0, loss = 0.011651\n",
      "epoch : 500.0, loss = 0.011738\n",
      "epoch : 501.0, loss = 0.011997\n",
      "epoch : 502.0, loss = 0.011650\n",
      "epoch : 503.0, loss = 0.011635\n",
      "epoch : 504.0, loss = 0.011752\n",
      "epoch : 505.0, loss = 0.011689\n",
      "epoch : 506.0, loss = 0.011648\n",
      "epoch : 507.0, loss = 0.011647\n",
      "epoch : 508.0, loss = 0.011873\n",
      "epoch : 509.0, loss = 0.011794\n",
      "epoch : 510.0, loss = 0.011627\n",
      "epoch : 511.0, loss = 0.011928\n",
      "epoch : 512.0, loss = 0.011623\n",
      "epoch : 513.0, loss = 0.011756\n",
      "epoch : 514.0, loss = 0.011795\n",
      "epoch : 515.0, loss = 0.011626\n",
      "epoch : 516.0, loss = 0.011886\n",
      "epoch : 517.0, loss = 0.011560\n",
      "epoch : 518.0, loss = 0.011720\n",
      "epoch : 519.0, loss = 0.011685\n",
      "epoch : 520.0, loss = 0.011894\n",
      "epoch : 521.0, loss = 0.011625\n",
      "epoch : 522.0, loss = 0.011739\n",
      "epoch : 523.0, loss = 0.011812\n",
      "epoch : 524.0, loss = 0.011810\n",
      "epoch : 525.0, loss = 0.011642\n",
      "epoch : 526.0, loss = 0.011979\n",
      "epoch : 527.0, loss = 0.011750\n",
      "epoch : 528.0, loss = 0.011708\n",
      "epoch : 529.0, loss = 0.011858\n",
      "epoch : 530.0, loss = 0.011718\n",
      "epoch : 531.0, loss = 0.011798\n",
      "epoch : 532.0, loss = 0.011763\n",
      "epoch : 533.0, loss = 0.011830\n",
      "epoch : 534.0, loss = 0.011517\n",
      "epoch : 535.0, loss = 0.011714\n",
      "epoch : 536.0, loss = 0.011829\n",
      "epoch : 537.0, loss = 0.011771\n",
      "epoch : 538.0, loss = 0.011635\n",
      "epoch : 539.0, loss = 0.011661\n",
      "epoch : 540.0, loss = 0.011781\n",
      "epoch : 541.0, loss = 0.011824\n",
      "epoch : 542.0, loss = 0.011763\n",
      "epoch : 543.0, loss = 0.011756\n",
      "epoch : 544.0, loss = 0.011757\n",
      "epoch : 545.0, loss = 0.011507\n",
      "epoch : 546.0, loss = 0.011553\n",
      "epoch : 547.0, loss = 0.011857\n",
      "epoch : 548.0, loss = 0.011902\n",
      "epoch : 549.0, loss = 0.011664\n",
      "epoch : 550.0, loss = 0.011729\n",
      "epoch : 551.0, loss = 0.011464\n",
      "epoch : 552.0, loss = 0.011662\n",
      "epoch : 553.0, loss = 0.011748\n",
      "epoch : 554.0, loss = 0.011729\n",
      "epoch : 555.0, loss = 0.011619\n",
      "epoch : 556.0, loss = 0.011598\n",
      "epoch : 557.0, loss = 0.011633\n",
      "epoch : 558.0, loss = 0.011680\n",
      "epoch : 559.0, loss = 0.011759\n",
      "epoch : 560.0, loss = 0.011348\n",
      "epoch : 561.0, loss = 0.011588\n",
      "epoch : 562.0, loss = 0.011755\n",
      "epoch : 563.0, loss = 0.011966\n",
      "epoch : 564.0, loss = 0.011876\n",
      "epoch : 565.0, loss = 0.011569\n",
      "epoch : 566.0, loss = 0.011663\n",
      "epoch : 567.0, loss = 0.012080\n",
      "epoch : 568.0, loss = 0.011528\n",
      "epoch : 569.0, loss = 0.011648\n",
      "epoch : 570.0, loss = 0.011638\n",
      "epoch : 571.0, loss = 0.011685\n",
      "epoch : 572.0, loss = 0.011387\n",
      "epoch : 573.0, loss = 0.011595\n",
      "epoch : 574.0, loss = 0.011723\n",
      "epoch : 575.0, loss = 0.011645\n",
      "epoch : 576.0, loss = 0.011653\n",
      "epoch : 577.0, loss = 0.011712\n",
      "epoch : 578.0, loss = 0.011671\n",
      "epoch : 579.0, loss = 0.011743\n",
      "epoch : 580.0, loss = 0.011717\n",
      "epoch : 581.0, loss = 0.011660\n",
      "epoch : 582.0, loss = 0.011773\n",
      "epoch : 583.0, loss = 0.011543\n",
      "epoch : 584.0, loss = 0.011722\n",
      "epoch : 585.0, loss = 0.011868\n",
      "epoch : 586.0, loss = 0.011725\n",
      "epoch : 587.0, loss = 0.011648\n",
      "epoch : 588.0, loss = 0.011705\n",
      "epoch : 589.0, loss = 0.011635\n",
      "epoch : 590.0, loss = 0.011685\n",
      "epoch : 591.0, loss = 0.011613\n",
      "epoch : 592.0, loss = 0.011674\n",
      "epoch : 593.0, loss = 0.011768\n",
      "epoch : 594.0, loss = 0.011801\n",
      "epoch : 595.0, loss = 0.011728\n",
      "epoch : 596.0, loss = 0.011725\n",
      "epoch : 597.0, loss = 0.011580\n",
      "epoch : 598.0, loss = 0.011821\n",
      "epoch : 599.0, loss = 0.011758\n",
      "epoch : 600.0, loss = 0.011679\n",
      "epoch : 601.0, loss = 0.011948\n",
      "epoch : 602.0, loss = 0.011566\n",
      "epoch : 603.0, loss = 0.011939\n",
      "epoch : 604.0, loss = 0.011686\n",
      "epoch : 605.0, loss = 0.011851\n",
      "epoch : 606.0, loss = 0.011590\n",
      "epoch : 607.0, loss = 0.011723\n",
      "epoch : 608.0, loss = 0.011647\n",
      "epoch : 609.0, loss = 0.011788\n",
      "epoch : 610.0, loss = 0.011835\n",
      "epoch : 611.0, loss = 0.011585\n",
      "epoch : 612.0, loss = 0.011740\n",
      "epoch : 613.0, loss = 0.011470\n",
      "epoch : 614.0, loss = 0.011928\n",
      "epoch : 615.0, loss = 0.011587\n",
      "epoch : 616.0, loss = 0.011906\n",
      "epoch : 617.0, loss = 0.011798\n",
      "epoch : 618.0, loss = 0.011689\n",
      "epoch : 619.0, loss = 0.011803\n",
      "epoch : 620.0, loss = 0.011585\n",
      "epoch : 621.0, loss = 0.011926\n",
      "epoch : 622.0, loss = 0.011716\n",
      "epoch : 623.0, loss = 0.011636\n",
      "epoch : 624.0, loss = 0.011763\n",
      "epoch : 625.0, loss = 0.011750\n",
      "epoch : 626.0, loss = 0.011678\n",
      "epoch : 627.0, loss = 0.011774\n",
      "epoch : 628.0, loss = 0.011672\n",
      "epoch : 629.0, loss = 0.011680\n",
      "epoch : 630.0, loss = 0.011782\n",
      "epoch : 631.0, loss = 0.011860\n",
      "epoch : 632.0, loss = 0.011778\n",
      "epoch : 633.0, loss = 0.011631\n",
      "epoch : 634.0, loss = 0.011696\n",
      "epoch : 635.0, loss = 0.011753\n",
      "epoch : 636.0, loss = 0.011630\n",
      "epoch : 637.0, loss = 0.011900\n",
      "epoch : 638.0, loss = 0.011651\n",
      "epoch : 639.0, loss = 0.011544\n",
      "epoch : 640.0, loss = 0.011621\n",
      "epoch : 641.0, loss = 0.011599\n",
      "epoch : 642.0, loss = 0.011788\n",
      "epoch : 643.0, loss = 0.011838\n",
      "epoch : 644.0, loss = 0.011762\n",
      "epoch : 645.0, loss = 0.011798\n",
      "epoch : 646.0, loss = 0.011759\n",
      "epoch : 647.0, loss = 0.011771\n",
      "epoch : 648.0, loss = 0.011778\n",
      "epoch : 649.0, loss = 0.011879\n",
      "epoch : 650.0, loss = 0.011602\n",
      "epoch : 651.0, loss = 0.011792\n",
      "epoch : 652.0, loss = 0.011648\n",
      "epoch : 653.0, loss = 0.011578\n",
      "epoch : 654.0, loss = 0.011666\n",
      "epoch : 655.0, loss = 0.011574\n",
      "epoch : 656.0, loss = 0.011950\n",
      "epoch : 657.0, loss = 0.011715\n",
      "epoch : 658.0, loss = 0.011578\n",
      "epoch : 659.0, loss = 0.011741\n",
      "epoch : 660.0, loss = 0.011810\n",
      "epoch : 661.0, loss = 0.011539\n"
     ]
    }
   ],
   "source": [
    "best_state_dict = train_autoencoder(10, batch_maker, optimizer, net, criterion,max_epochs=6600)\n",
    "#net.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(wd_path, \"models\")\n",
    "\n",
    "net.save_model(os.path.join(models_path, \"ae_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=1)\n",
    "images = next(batch_maker)\n",
    "\n",
    "images = images.to(device)\n",
    "x_r = net.encode(images[0].view(3*8*8))\n",
    "x_rebuilt_r = net.decode(x_r).detach().cpu().view(3,8,8)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(x_rebuilt_r))\n",
    "print(\"Original\")\n",
    "imshow(images[0].detach().cpu().view(3,8,8))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (activation): ReLU()\n",
       "  (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
       "  (fc2): Linear(in_features=96, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=96, bias=True)\n",
       "  (fc4): Linear(in_features=96, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = os.path.join(wd_path, \"models\")\n",
    "loaded_autoencoder = AutoEncoder.load_autoencoder(os.path.join(models_path, \"ae_0.pt\"))\n",
    "loaded_autoencoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Reconstructed\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEOUlEQVR4nO3dvVKbVxRA0SuERBznVTMTP1uKzOSV8uMIGwwCpBRuZVXJ8S7WKqE495O0dWcoOJvz+byAnpvvfQDgMnFClDghSpwQJU6Iur32yw8//zL2p9z373+aGrV+fPdubNZaa21vtmOzDofD2Ky//vxjbNY/Hz+OzVprrccvj2Ozfv39t82ln7s5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEHV1HcPx6WnqHKMrC242F//7/f9mM/hsz8/HsVkPDw9jsz4PzlprrU8Pn0fnXeLmhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTVdQwPj49T51hrcEXCZjP7nXR6O43NOhwOY7PuP82tLPh78LnWWuvL4+z6h0vcnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Rd3ZXy/PQ0dY51Pp/HZr0N7i75am4PzP395K6UuVmfB2ettdbx+DI67xI3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6KurmM4nefWFpxOk+sY3sZmfZ039zoeX45js56en8dmvb6+js1aa62XwdfxW9ycECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiLq6juH2djd1jrW73Y7N2u/nnmuttV5e59Y/7Aafbb+bm3Wznft8rLXWdnjeJW5OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRF1dx7Ab/Hf7+7sfxmbt9vuxWWutdbOdW8dwd3c3Nms/OWv4PTu9zb1n3+LmhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IerqrpTb2+3UOdZ28Gti/BvpZjM2ajv4Qu53Vz8+/6m7/dzenrXWOp9Oo/MucXNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanM+n7/3GYAL3JwQJU6IEidEiROixAlR4oSofwFA8G57pz7TMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEy0lEQVR4nO3dsWudZRjG4efYhKYWBVGERpvUKjXZKlIntw4dHCqhiCC4qEtRcHFycdHWlFa3ri7+AzqJCGkH0ZK0BUNRB1FETUvUGKUlxPb4D5yeSZ7ehesazzfcHwd+54WzvIPhcFhAnnvu9AsAo4kTQokTQokTQokTQk2Me/jsk8+0/ZW7eOpk11Tt3DHZtlVVVbe226ZeWDjatnVp5ULb1vrab21bVVVvvvF629Yn310ZjPrcyQmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhBuMuz9374EzbdQxbN653TdX83FzbVlXVi8cW2rZubvV9j7smd7RtnVl8v22rqmr3vVNtWxfW1lzHAHcTcUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUKoiXEPP/1yqek1qnZOTbZtfXjqdNtWVdXxt99q25qfe6Jta/rhh9q21murbauq6trmP617ozg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTYu1IOH32u6z3qjz/X27ZqY7Nvq6re+WCxbevc55+1bR1beL5t6+Lq5batqqrDR4607o3i5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQg+FweNuHH59fuv3D/9n+/fu6pury8krbVlXV6RPvtW29+vJLbVuLJ95t2zowO9u2VVW1snypbWt7azgY9bmTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KNvY5hcnam7TqGfzc3uqZqemZf21ZV1fHXXmnb+ur8UtvW6sXltq3fr11t26qqmpne07a1+u1PrmOAu4k4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTEuIdff3Gu6z3qgfvva9u6+vMvbVtVVTf+/qtt69Fdu9u2fv3mStvW9COPtW1VVd26ud26N4qTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KNvSvl6QPzXe9RNdH3O/H43tm2raqqH3/4vm3ro7Nn27amGn/br29stG1VVR166mDr3ihOTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgg1GA6Hd/odgBGcnBBKnBBKnBBKnBBKnBBKnBDqP4Z5e95b1xafAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "batch_maker = get_tile_batch([os.path.join(wd_path, \"images\",\"val_0_0.jpeg\")],batch_size=1)\n",
    "images = next(batch_maker)\n",
    "images = images.to(device)\n",
    "\n",
    "print(\"Original\")\n",
    "\n",
    "x_r = loaded_autoencoder.encode(images.view(-1,3*8*8))\n",
    "x_rebuilt_r = loaded_autoencoder.decode(x_r).detach().cpu().view(3,8,8)\n",
    "\n",
    "print(\"Reconstructed\")\n",
    "# show images\n",
    "imshow(x_rebuilt_r)\n",
    "print(\"Original\")\n",
    "\n",
    "imshow(images[0].detach().cpu().view(3,8,8))\n",
    "# print labels"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80eecae6fe367bf31bafaafee0935a4935edb539e731c9082f4e2c31e5b4f550"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
