{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, features\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ae import AutoEncoder\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/introduction')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using the device\",device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def take_random_tile(img_raw,tile_size=8,sample_shape_range=None):\n",
    "    channels, width,height=list(img_raw.shape) #(3,width,height)\n",
    "\n",
    "    if sample_shape_range != None:\n",
    "        min_size, max_size = sample_shape_range\n",
    "\n",
    "        tile_size = randint(min_size,max_size)\n",
    "\n",
    "        if tile_size > width or tile_size > height: #correct for sample sizes bigger than the image\n",
    "            tile_size = min(height,width)\n",
    "    \n",
    "    top  = randint(0,width-tile_size)\n",
    "    left = randint(0,height-tile_size)\n",
    "\n",
    "    tile_tensor = img_raw[:,top:top+tile_size,left:left+tile_size] #tile\n",
    "    #print(list(tile_tensor.shape))\n",
    "\n",
    "    if sample_shape_range != None:\n",
    "        tile_tensor = F.interpolate(tile_tensor,size=(channels,tile_size,tile_size))\n",
    "    return tile_tensor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def get_tile_batch(image_list, batch_size=1000, tile_size=8, sample_shape_range=None):\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    while True:\n",
    "        tile_list = [] #initialize batch tensor\n",
    "        for i in range(batch_size):\n",
    "            next_image,=sample(image_list,k=1)\n",
    "            image_tensor = convert_tensor(Image.open(next_image).convert('RGB'))\n",
    "            tile = take_random_tile(image_tensor,tile_size,sample_shape_range)\n",
    "            #print(tile.shape)\n",
    "            tile_list.append(tile)\n",
    "\n",
    "        batch = torch.stack(tile_list)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "wd_path = os.path.abspath(os.getcwd())\n",
    "root_path = os.path.join(wd_path, \"datasets\", 'ImageNet','train')\n",
    "\n",
    "\n",
    "image_path_list = []\n",
    "for d in listdir(root_path):\n",
    "    #d = n016...\n",
    "    class_path = join(root_path,d,\"images\")\n",
    "    for i in listdir(class_path):\n",
    "        #i = n016..._n.JPEG\n",
    "        image_path_list.append(join(class_path,i))\n",
    "\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=8)\n",
    "sample_images = next(batch_maker)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(sample_images))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(epoch_size, train_loader,optimizer,model,criterion,max_epochs):\n",
    "    training_loss_history= []\n",
    "    loss = 0\n",
    "    min_loss = 1\n",
    "    for epoch_number,tiles in enumerate(train_loader):\n",
    "\n",
    "        # reshape mini-batch data to [N, 3*8*8] matrix\n",
    "        # load it to the active device\n",
    "        tiles = tiles.to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(tiles)                 # compute reconstructions\n",
    "        train_loss = criterion(outputs, tiles.view(-1, 3*8*8)) # compute training reconstruction loss\n",
    "        train_loss.backward()                  # compute accumulated gradients\n",
    "        optimizer.step()                       # perform parameter update based on current gradients\n",
    "        loss += train_loss.item()              # add the mini-batch training loss to epoch loss\n",
    "        \n",
    "        if epoch_number%epoch_size == epoch_size-1:\n",
    "            # compute the epoch training loss\n",
    "            loss = loss / epoch_size\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_params = model.state_dict()\n",
    "            # display the epoch training loss\n",
    "            print(f\"epoch : {(epoch_number+1)/epoch_size}, loss = {loss:.6f}\")\n",
    "            training_loss_history.append(loss)\n",
    "            loss = 0\n",
    "            if(epoch_number >= max_epochs):\n",
    "                return best_params\n",
    "                \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vector_size = 10\n",
    "net = AutoEncoder(hidden_sizes=[32*3,c_vector_size,32*3])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "batch_maker = get_tile_batch(image_path_list,tile_size=8,batch_size=1000)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1.0, loss = 0.011675\n",
      "epoch : 2.0, loss = 0.011672\n",
      "epoch : 3.0, loss = 0.011634\n",
      "epoch : 4.0, loss = 0.011494\n",
      "epoch : 5.0, loss = 0.011599\n",
      "epoch : 6.0, loss = 0.011546\n",
      "epoch : 7.0, loss = 0.011729\n",
      "epoch : 8.0, loss = 0.011648\n",
      "epoch : 9.0, loss = 0.011710\n",
      "epoch : 10.0, loss = 0.011583\n",
      "epoch : 11.0, loss = 0.011692\n",
      "epoch : 12.0, loss = 0.011470\n",
      "epoch : 13.0, loss = 0.011478\n",
      "epoch : 14.0, loss = 0.011527\n",
      "epoch : 15.0, loss = 0.011724\n",
      "epoch : 16.0, loss = 0.011742\n",
      "epoch : 17.0, loss = 0.011719\n",
      "epoch : 18.0, loss = 0.011682\n",
      "epoch : 19.0, loss = 0.011686\n",
      "epoch : 20.0, loss = 0.011492\n",
      "epoch : 21.0, loss = 0.011542\n",
      "epoch : 22.0, loss = 0.011656\n",
      "epoch : 23.0, loss = 0.011522\n",
      "epoch : 24.0, loss = 0.011553\n",
      "epoch : 25.0, loss = 0.011610\n",
      "epoch : 26.0, loss = 0.011615\n",
      "epoch : 27.0, loss = 0.011736\n",
      "epoch : 28.0, loss = 0.011749\n",
      "epoch : 29.0, loss = 0.011612\n",
      "epoch : 30.0, loss = 0.011838\n",
      "epoch : 31.0, loss = 0.011663\n",
      "epoch : 32.0, loss = 0.011675\n",
      "epoch : 33.0, loss = 0.011550\n",
      "epoch : 34.0, loss = 0.011537\n",
      "epoch : 35.0, loss = 0.011833\n",
      "epoch : 36.0, loss = 0.011761\n",
      "epoch : 37.0, loss = 0.011665\n",
      "epoch : 38.0, loss = 0.011696\n",
      "epoch : 39.0, loss = 0.011839\n",
      "epoch : 40.0, loss = 0.011664\n",
      "epoch : 41.0, loss = 0.011486\n",
      "epoch : 42.0, loss = 0.011677\n",
      "epoch : 43.0, loss = 0.011572\n",
      "epoch : 44.0, loss = 0.011324\n",
      "epoch : 45.0, loss = 0.011637\n",
      "epoch : 46.0, loss = 0.011722\n",
      "epoch : 47.0, loss = 0.011593\n",
      "epoch : 48.0, loss = 0.011626\n",
      "epoch : 49.0, loss = 0.011555\n",
      "epoch : 50.0, loss = 0.011528\n",
      "epoch : 51.0, loss = 0.011695\n",
      "epoch : 52.0, loss = 0.011722\n",
      "epoch : 53.0, loss = 0.011483\n",
      "epoch : 54.0, loss = 0.011844\n",
      "epoch : 55.0, loss = 0.011566\n",
      "epoch : 56.0, loss = 0.011739\n",
      "epoch : 57.0, loss = 0.011890\n",
      "epoch : 58.0, loss = 0.011652\n",
      "epoch : 59.0, loss = 0.011673\n",
      "epoch : 60.0, loss = 0.011932\n",
      "epoch : 61.0, loss = 0.011453\n",
      "epoch : 62.0, loss = 0.011572\n",
      "epoch : 63.0, loss = 0.011639\n",
      "epoch : 64.0, loss = 0.011738\n",
      "epoch : 65.0, loss = 0.011546\n",
      "epoch : 66.0, loss = 0.011517\n",
      "epoch : 67.0, loss = 0.011762\n",
      "epoch : 68.0, loss = 0.011521\n",
      "epoch : 69.0, loss = 0.011602\n",
      "epoch : 70.0, loss = 0.011625\n",
      "epoch : 71.0, loss = 0.011587\n",
      "epoch : 72.0, loss = 0.011714\n",
      "epoch : 73.0, loss = 0.011653\n",
      "epoch : 74.0, loss = 0.011789\n",
      "epoch : 75.0, loss = 0.011758\n",
      "epoch : 76.0, loss = 0.011620\n",
      "epoch : 77.0, loss = 0.011782\n",
      "epoch : 78.0, loss = 0.011644\n",
      "epoch : 79.0, loss = 0.011859\n",
      "epoch : 80.0, loss = 0.011870\n",
      "epoch : 81.0, loss = 0.011608\n",
      "epoch : 82.0, loss = 0.011549\n",
      "epoch : 83.0, loss = 0.011559\n",
      "epoch : 84.0, loss = 0.011650\n",
      "epoch : 85.0, loss = 0.011871\n",
      "epoch : 86.0, loss = 0.011345\n",
      "epoch : 87.0, loss = 0.011495\n",
      "epoch : 88.0, loss = 0.011621\n",
      "epoch : 89.0, loss = 0.011564\n",
      "epoch : 90.0, loss = 0.011541\n",
      "epoch : 91.0, loss = 0.011762\n",
      "epoch : 92.0, loss = 0.011681\n",
      "epoch : 93.0, loss = 0.011641\n",
      "epoch : 94.0, loss = 0.011743\n",
      "epoch : 95.0, loss = 0.011632\n",
      "epoch : 96.0, loss = 0.011885\n",
      "epoch : 97.0, loss = 0.011538\n",
      "epoch : 98.0, loss = 0.011686\n",
      "epoch : 99.0, loss = 0.011525\n",
      "epoch : 100.0, loss = 0.011573\n",
      "epoch : 101.0, loss = 0.011748\n",
      "epoch : 102.0, loss = 0.011822\n",
      "epoch : 103.0, loss = 0.011771\n",
      "epoch : 104.0, loss = 0.011748\n",
      "epoch : 105.0, loss = 0.011634\n",
      "epoch : 106.0, loss = 0.011654\n",
      "epoch : 107.0, loss = 0.011687\n",
      "epoch : 108.0, loss = 0.011517\n",
      "epoch : 109.0, loss = 0.011883\n",
      "epoch : 110.0, loss = 0.011622\n",
      "epoch : 111.0, loss = 0.011781\n",
      "epoch : 112.0, loss = 0.011444\n",
      "epoch : 113.0, loss = 0.011565\n",
      "epoch : 114.0, loss = 0.011582\n",
      "epoch : 115.0, loss = 0.011723\n",
      "epoch : 116.0, loss = 0.011558\n",
      "epoch : 117.0, loss = 0.011548\n",
      "epoch : 118.0, loss = 0.011764\n",
      "epoch : 119.0, loss = 0.011561\n",
      "epoch : 120.0, loss = 0.011770\n",
      "epoch : 121.0, loss = 0.011864\n",
      "epoch : 122.0, loss = 0.011713\n",
      "epoch : 123.0, loss = 0.011449\n",
      "epoch : 124.0, loss = 0.011633\n",
      "epoch : 125.0, loss = 0.011620\n",
      "epoch : 126.0, loss = 0.011842\n",
      "epoch : 127.0, loss = 0.011548\n",
      "epoch : 128.0, loss = 0.011534\n",
      "epoch : 129.0, loss = 0.011624\n",
      "epoch : 130.0, loss = 0.011685\n",
      "epoch : 131.0, loss = 0.011756\n",
      "epoch : 132.0, loss = 0.011757\n",
      "epoch : 133.0, loss = 0.011693\n",
      "epoch : 134.0, loss = 0.011757\n",
      "epoch : 135.0, loss = 0.011660\n",
      "epoch : 136.0, loss = 0.011609\n",
      "epoch : 137.0, loss = 0.011807\n",
      "epoch : 138.0, loss = 0.011561\n",
      "epoch : 139.0, loss = 0.011984\n",
      "epoch : 140.0, loss = 0.011891\n",
      "epoch : 141.0, loss = 0.011707\n",
      "epoch : 142.0, loss = 0.011787\n",
      "epoch : 143.0, loss = 0.011721\n",
      "epoch : 144.0, loss = 0.011760\n",
      "epoch : 145.0, loss = 0.011743\n",
      "epoch : 146.0, loss = 0.011671\n",
      "epoch : 147.0, loss = 0.011855\n",
      "epoch : 148.0, loss = 0.011690\n",
      "epoch : 149.0, loss = 0.011762\n",
      "epoch : 150.0, loss = 0.011693\n",
      "epoch : 151.0, loss = 0.011507\n",
      "epoch : 152.0, loss = 0.011657\n",
      "epoch : 153.0, loss = 0.011780\n",
      "epoch : 154.0, loss = 0.011584\n",
      "epoch : 155.0, loss = 0.011520\n",
      "epoch : 156.0, loss = 0.011542\n",
      "epoch : 157.0, loss = 0.011601\n",
      "epoch : 158.0, loss = 0.011813\n",
      "epoch : 159.0, loss = 0.011457\n",
      "epoch : 160.0, loss = 0.011707\n",
      "epoch : 161.0, loss = 0.011587\n",
      "epoch : 162.0, loss = 0.011754\n",
      "epoch : 163.0, loss = 0.011679\n",
      "epoch : 164.0, loss = 0.011545\n",
      "epoch : 165.0, loss = 0.011778\n",
      "epoch : 166.0, loss = 0.011485\n",
      "epoch : 167.0, loss = 0.011643\n",
      "epoch : 168.0, loss = 0.011560\n",
      "epoch : 169.0, loss = 0.011629\n",
      "epoch : 170.0, loss = 0.011589\n",
      "epoch : 171.0, loss = 0.011599\n",
      "epoch : 172.0, loss = 0.011940\n",
      "epoch : 173.0, loss = 0.011575\n",
      "epoch : 174.0, loss = 0.011641\n",
      "epoch : 175.0, loss = 0.011725\n",
      "epoch : 176.0, loss = 0.011656\n",
      "epoch : 177.0, loss = 0.011422\n",
      "epoch : 178.0, loss = 0.011920\n",
      "epoch : 179.0, loss = 0.011621\n",
      "epoch : 180.0, loss = 0.011645\n",
      "epoch : 181.0, loss = 0.011738\n",
      "epoch : 182.0, loss = 0.011617\n",
      "epoch : 183.0, loss = 0.011672\n",
      "epoch : 184.0, loss = 0.011478\n",
      "epoch : 185.0, loss = 0.011497\n",
      "epoch : 186.0, loss = 0.011469\n",
      "epoch : 187.0, loss = 0.011615\n",
      "epoch : 188.0, loss = 0.011725\n",
      "epoch : 189.0, loss = 0.011670\n",
      "epoch : 190.0, loss = 0.011685\n",
      "epoch : 191.0, loss = 0.011394\n",
      "epoch : 192.0, loss = 0.011476\n",
      "epoch : 193.0, loss = 0.011833\n",
      "epoch : 194.0, loss = 0.011502\n",
      "epoch : 195.0, loss = 0.011595\n",
      "epoch : 196.0, loss = 0.011752\n",
      "epoch : 197.0, loss = 0.011690\n",
      "epoch : 198.0, loss = 0.011640\n",
      "epoch : 199.0, loss = 0.011544\n",
      "epoch : 200.0, loss = 0.011487\n",
      "epoch : 201.0, loss = 0.011583\n",
      "epoch : 202.0, loss = 0.011728\n",
      "epoch : 203.0, loss = 0.011720\n",
      "epoch : 204.0, loss = 0.011562\n",
      "epoch : 205.0, loss = 0.011766\n",
      "epoch : 206.0, loss = 0.011842\n",
      "epoch : 207.0, loss = 0.011585\n",
      "epoch : 208.0, loss = 0.011399\n",
      "epoch : 209.0, loss = 0.011808\n",
      "epoch : 210.0, loss = 0.011687\n",
      "epoch : 211.0, loss = 0.011798\n",
      "epoch : 212.0, loss = 0.011493\n",
      "epoch : 213.0, loss = 0.011626\n",
      "epoch : 214.0, loss = 0.011484\n",
      "epoch : 215.0, loss = 0.011667\n",
      "epoch : 216.0, loss = 0.011742\n",
      "epoch : 217.0, loss = 0.011686\n",
      "epoch : 218.0, loss = 0.011507\n",
      "epoch : 219.0, loss = 0.011719\n",
      "epoch : 220.0, loss = 0.011573\n",
      "epoch : 221.0, loss = 0.011669\n",
      "epoch : 222.0, loss = 0.011496\n",
      "epoch : 223.0, loss = 0.011708\n",
      "epoch : 224.0, loss = 0.011573\n",
      "epoch : 225.0, loss = 0.011843\n",
      "epoch : 226.0, loss = 0.011771\n",
      "epoch : 227.0, loss = 0.011661\n",
      "epoch : 228.0, loss = 0.011576\n",
      "epoch : 229.0, loss = 0.011925\n",
      "epoch : 230.0, loss = 0.011453\n",
      "epoch : 231.0, loss = 0.011528\n",
      "epoch : 232.0, loss = 0.011487\n",
      "epoch : 233.0, loss = 0.011540\n",
      "epoch : 234.0, loss = 0.011467\n",
      "epoch : 235.0, loss = 0.011612\n",
      "epoch : 236.0, loss = 0.011574\n",
      "epoch : 237.0, loss = 0.011652\n",
      "epoch : 238.0, loss = 0.011662\n",
      "epoch : 239.0, loss = 0.011856\n",
      "epoch : 240.0, loss = 0.011632\n",
      "epoch : 241.0, loss = 0.011525\n",
      "epoch : 242.0, loss = 0.011685\n",
      "epoch : 243.0, loss = 0.011499\n",
      "epoch : 244.0, loss = 0.011573\n",
      "epoch : 245.0, loss = 0.011648\n",
      "epoch : 246.0, loss = 0.011347\n",
      "epoch : 247.0, loss = 0.011612\n",
      "epoch : 248.0, loss = 0.011582\n",
      "epoch : 249.0, loss = 0.011780\n",
      "epoch : 250.0, loss = 0.011585\n",
      "epoch : 251.0, loss = 0.011968\n",
      "epoch : 252.0, loss = 0.011651\n",
      "epoch : 253.0, loss = 0.011713\n",
      "epoch : 254.0, loss = 0.011530\n",
      "epoch : 255.0, loss = 0.011537\n",
      "epoch : 256.0, loss = 0.011639\n",
      "epoch : 257.0, loss = 0.011802\n",
      "epoch : 258.0, loss = 0.011770\n",
      "epoch : 259.0, loss = 0.011552\n",
      "epoch : 260.0, loss = 0.011628\n",
      "epoch : 261.0, loss = 0.011604\n",
      "epoch : 262.0, loss = 0.011382\n",
      "epoch : 263.0, loss = 0.011569\n",
      "epoch : 264.0, loss = 0.011594\n",
      "epoch : 265.0, loss = 0.011533\n",
      "epoch : 266.0, loss = 0.011715\n",
      "epoch : 267.0, loss = 0.011592\n",
      "epoch : 268.0, loss = 0.011450\n",
      "epoch : 269.0, loss = 0.011787\n",
      "epoch : 270.0, loss = 0.011756\n",
      "epoch : 271.0, loss = 0.011648\n",
      "epoch : 272.0, loss = 0.011765\n",
      "epoch : 273.0, loss = 0.011754\n",
      "epoch : 274.0, loss = 0.011821\n",
      "epoch : 275.0, loss = 0.011571\n",
      "epoch : 276.0, loss = 0.011718\n",
      "epoch : 277.0, loss = 0.011992\n",
      "epoch : 278.0, loss = 0.011556\n",
      "epoch : 279.0, loss = 0.011663\n",
      "epoch : 280.0, loss = 0.011429\n",
      "epoch : 281.0, loss = 0.011563\n",
      "epoch : 282.0, loss = 0.011567\n",
      "epoch : 283.0, loss = 0.011376\n",
      "epoch : 284.0, loss = 0.011755\n",
      "epoch : 285.0, loss = 0.011604\n",
      "epoch : 286.0, loss = 0.011533\n",
      "epoch : 287.0, loss = 0.011589\n",
      "epoch : 288.0, loss = 0.011455\n",
      "epoch : 289.0, loss = 0.011636\n",
      "epoch : 290.0, loss = 0.011667\n",
      "epoch : 291.0, loss = 0.011616\n",
      "epoch : 292.0, loss = 0.011543\n",
      "epoch : 293.0, loss = 0.011714\n",
      "epoch : 294.0, loss = 0.011835\n",
      "epoch : 295.0, loss = 0.011674\n",
      "epoch : 296.0, loss = 0.011776\n",
      "epoch : 297.0, loss = 0.011548\n",
      "epoch : 298.0, loss = 0.011374\n",
      "epoch : 299.0, loss = 0.011551\n",
      "epoch : 300.0, loss = 0.011577\n",
      "epoch : 301.0, loss = 0.011585\n",
      "epoch : 302.0, loss = 0.011655\n",
      "epoch : 303.0, loss = 0.011838\n",
      "epoch : 304.0, loss = 0.011608\n",
      "epoch : 305.0, loss = 0.011595\n",
      "epoch : 306.0, loss = 0.011493\n",
      "epoch : 307.0, loss = 0.011495\n",
      "epoch : 308.0, loss = 0.011688\n",
      "epoch : 309.0, loss = 0.011741\n",
      "epoch : 310.0, loss = 0.011506\n",
      "epoch : 311.0, loss = 0.011682\n",
      "epoch : 312.0, loss = 0.011567\n",
      "epoch : 313.0, loss = 0.011650\n",
      "epoch : 314.0, loss = 0.011380\n",
      "epoch : 315.0, loss = 0.011564\n",
      "epoch : 316.0, loss = 0.011692\n",
      "epoch : 317.0, loss = 0.011577\n",
      "epoch : 318.0, loss = 0.012016\n",
      "epoch : 319.0, loss = 0.011500\n",
      "epoch : 320.0, loss = 0.011699\n",
      "epoch : 321.0, loss = 0.011684\n",
      "epoch : 322.0, loss = 0.011474\n",
      "epoch : 323.0, loss = 0.011630\n",
      "epoch : 324.0, loss = 0.011792\n",
      "epoch : 325.0, loss = 0.011715\n",
      "epoch : 326.0, loss = 0.011481\n",
      "epoch : 327.0, loss = 0.011599\n",
      "epoch : 328.0, loss = 0.011438\n",
      "epoch : 329.0, loss = 0.011475\n",
      "epoch : 330.0, loss = 0.011613\n",
      "epoch : 331.0, loss = 0.011496\n",
      "epoch : 332.0, loss = 0.011550\n",
      "epoch : 333.0, loss = 0.011526\n",
      "epoch : 334.0, loss = 0.011876\n",
      "epoch : 335.0, loss = 0.011677\n",
      "epoch : 336.0, loss = 0.011695\n",
      "epoch : 337.0, loss = 0.011743\n",
      "epoch : 338.0, loss = 0.011817\n",
      "epoch : 339.0, loss = 0.011622\n",
      "epoch : 340.0, loss = 0.011518\n",
      "epoch : 341.0, loss = 0.011697\n",
      "epoch : 342.0, loss = 0.011598\n",
      "epoch : 343.0, loss = 0.011579\n",
      "epoch : 344.0, loss = 0.011559\n",
      "epoch : 345.0, loss = 0.011705\n",
      "epoch : 346.0, loss = 0.011518\n",
      "epoch : 347.0, loss = 0.011621\n",
      "epoch : 348.0, loss = 0.011669\n",
      "epoch : 349.0, loss = 0.011351\n",
      "epoch : 350.0, loss = 0.011609\n",
      "epoch : 351.0, loss = 0.011644\n",
      "epoch : 352.0, loss = 0.011576\n",
      "epoch : 353.0, loss = 0.011551\n",
      "epoch : 354.0, loss = 0.011453\n",
      "epoch : 355.0, loss = 0.011516\n",
      "epoch : 356.0, loss = 0.011614\n",
      "epoch : 357.0, loss = 0.011549\n",
      "epoch : 358.0, loss = 0.011409\n",
      "epoch : 359.0, loss = 0.011570\n",
      "epoch : 360.0, loss = 0.011739\n",
      "epoch : 361.0, loss = 0.011565\n",
      "epoch : 362.0, loss = 0.011640\n",
      "epoch : 363.0, loss = 0.011712\n",
      "epoch : 364.0, loss = 0.011798\n",
      "epoch : 365.0, loss = 0.011632\n",
      "epoch : 366.0, loss = 0.011676\n",
      "epoch : 367.0, loss = 0.011539\n",
      "epoch : 368.0, loss = 0.011559\n",
      "epoch : 369.0, loss = 0.011639\n",
      "epoch : 370.0, loss = 0.011845\n",
      "epoch : 371.0, loss = 0.011429\n",
      "epoch : 372.0, loss = 0.011620\n",
      "epoch : 373.0, loss = 0.011572\n",
      "epoch : 374.0, loss = 0.011597\n",
      "epoch : 375.0, loss = 0.011615\n",
      "epoch : 376.0, loss = 0.011356\n",
      "epoch : 377.0, loss = 0.011784\n",
      "epoch : 378.0, loss = 0.011436\n",
      "epoch : 379.0, loss = 0.011705\n",
      "epoch : 380.0, loss = 0.011685\n",
      "epoch : 381.0, loss = 0.011413\n",
      "epoch : 382.0, loss = 0.011755\n",
      "epoch : 383.0, loss = 0.011509\n",
      "epoch : 384.0, loss = 0.011546\n",
      "epoch : 385.0, loss = 0.011564\n",
      "epoch : 386.0, loss = 0.011857\n",
      "epoch : 387.0, loss = 0.011550\n",
      "epoch : 388.0, loss = 0.011702\n",
      "epoch : 389.0, loss = 0.011329\n",
      "epoch : 390.0, loss = 0.011689\n",
      "epoch : 391.0, loss = 0.011656\n",
      "epoch : 392.0, loss = 0.011730\n",
      "epoch : 393.0, loss = 0.011724\n",
      "epoch : 394.0, loss = 0.011577\n",
      "epoch : 395.0, loss = 0.011632\n",
      "epoch : 396.0, loss = 0.011534\n",
      "epoch : 397.0, loss = 0.011650\n",
      "epoch : 398.0, loss = 0.011583\n",
      "epoch : 399.0, loss = 0.011654\n",
      "epoch : 400.0, loss = 0.011456\n",
      "epoch : 401.0, loss = 0.011666\n",
      "epoch : 402.0, loss = 0.011697\n",
      "epoch : 403.0, loss = 0.011816\n",
      "epoch : 404.0, loss = 0.011533\n",
      "epoch : 405.0, loss = 0.011509\n",
      "epoch : 406.0, loss = 0.011682\n",
      "epoch : 407.0, loss = 0.011702\n",
      "epoch : 408.0, loss = 0.011682\n",
      "epoch : 409.0, loss = 0.011891\n",
      "epoch : 410.0, loss = 0.011611\n",
      "epoch : 411.0, loss = 0.011480\n",
      "epoch : 412.0, loss = 0.011721\n",
      "epoch : 413.0, loss = 0.011490\n",
      "epoch : 414.0, loss = 0.011682\n",
      "epoch : 415.0, loss = 0.011489\n",
      "epoch : 416.0, loss = 0.011453\n",
      "epoch : 417.0, loss = 0.011503\n",
      "epoch : 418.0, loss = 0.011490\n",
      "epoch : 419.0, loss = 0.011689\n",
      "epoch : 420.0, loss = 0.011525\n",
      "epoch : 421.0, loss = 0.011750\n",
      "epoch : 422.0, loss = 0.011736\n",
      "epoch : 423.0, loss = 0.011642\n",
      "epoch : 424.0, loss = 0.011734\n",
      "epoch : 425.0, loss = 0.011713\n",
      "epoch : 426.0, loss = 0.011576\n",
      "epoch : 427.0, loss = 0.011426\n",
      "epoch : 428.0, loss = 0.011670\n",
      "epoch : 429.0, loss = 0.011595\n",
      "epoch : 430.0, loss = 0.011683\n",
      "epoch : 431.0, loss = 0.011683\n",
      "epoch : 432.0, loss = 0.011638\n",
      "epoch : 433.0, loss = 0.011820\n",
      "epoch : 434.0, loss = 0.011395\n",
      "epoch : 435.0, loss = 0.011875\n",
      "epoch : 436.0, loss = 0.011579\n",
      "epoch : 437.0, loss = 0.011742\n",
      "epoch : 438.0, loss = 0.011431\n",
      "epoch : 439.0, loss = 0.011675\n",
      "epoch : 440.0, loss = 0.011659\n",
      "epoch : 441.0, loss = 0.011547\n",
      "epoch : 442.0, loss = 0.011653\n",
      "epoch : 443.0, loss = 0.011491\n",
      "epoch : 444.0, loss = 0.011586\n",
      "epoch : 445.0, loss = 0.011601\n",
      "epoch : 446.0, loss = 0.011506\n",
      "epoch : 447.0, loss = 0.011737\n",
      "epoch : 448.0, loss = 0.011440\n",
      "epoch : 449.0, loss = 0.011540\n",
      "epoch : 450.0, loss = 0.011667\n",
      "epoch : 451.0, loss = 0.011742\n",
      "epoch : 452.0, loss = 0.011513\n",
      "epoch : 453.0, loss = 0.011481\n",
      "epoch : 454.0, loss = 0.011481\n",
      "epoch : 455.0, loss = 0.011725\n",
      "epoch : 456.0, loss = 0.011728\n",
      "epoch : 457.0, loss = 0.011767\n",
      "epoch : 458.0, loss = 0.011709\n",
      "epoch : 459.0, loss = 0.011752\n",
      "epoch : 460.0, loss = 0.011759\n",
      "epoch : 461.0, loss = 0.011848\n",
      "epoch : 462.0, loss = 0.011761\n",
      "epoch : 463.0, loss = 0.011637\n",
      "epoch : 464.0, loss = 0.011633\n",
      "epoch : 465.0, loss = 0.011681\n",
      "epoch : 466.0, loss = 0.011706\n",
      "epoch : 467.0, loss = 0.011651\n",
      "epoch : 468.0, loss = 0.011633\n",
      "epoch : 469.0, loss = 0.011758\n",
      "epoch : 470.0, loss = 0.011657\n",
      "epoch : 471.0, loss = 0.011701\n",
      "epoch : 472.0, loss = 0.011644\n",
      "epoch : 473.0, loss = 0.011729\n",
      "epoch : 474.0, loss = 0.011583\n",
      "epoch : 475.0, loss = 0.011629\n",
      "epoch : 476.0, loss = 0.011550\n",
      "epoch : 477.0, loss = 0.011627\n",
      "epoch : 478.0, loss = 0.012055\n",
      "epoch : 479.0, loss = 0.011800\n",
      "epoch : 480.0, loss = 0.011635\n",
      "epoch : 481.0, loss = 0.011424\n",
      "epoch : 482.0, loss = 0.011380\n",
      "epoch : 483.0, loss = 0.011501\n",
      "epoch : 484.0, loss = 0.011552\n",
      "epoch : 485.0, loss = 0.011652\n",
      "epoch : 486.0, loss = 0.011887\n",
      "epoch : 487.0, loss = 0.011729\n",
      "epoch : 488.0, loss = 0.011642\n",
      "epoch : 489.0, loss = 0.011679\n",
      "epoch : 490.0, loss = 0.011487\n",
      "epoch : 491.0, loss = 0.011483\n",
      "epoch : 492.0, loss = 0.011598\n",
      "epoch : 493.0, loss = 0.011447\n",
      "epoch : 494.0, loss = 0.011716\n",
      "epoch : 495.0, loss = 0.011790\n",
      "epoch : 496.0, loss = 0.011595\n",
      "epoch : 497.0, loss = 0.011550\n",
      "epoch : 498.0, loss = 0.011797\n",
      "epoch : 499.0, loss = 0.011614\n",
      "epoch : 500.0, loss = 0.011529\n",
      "epoch : 501.0, loss = 0.011619\n",
      "epoch : 502.0, loss = 0.011778\n",
      "epoch : 503.0, loss = 0.011687\n",
      "epoch : 504.0, loss = 0.011596\n",
      "epoch : 505.0, loss = 0.011585\n",
      "epoch : 506.0, loss = 0.011537\n",
      "epoch : 507.0, loss = 0.011752\n",
      "epoch : 508.0, loss = 0.011760\n",
      "epoch : 509.0, loss = 0.011516\n",
      "epoch : 510.0, loss = 0.011586\n",
      "epoch : 511.0, loss = 0.011436\n",
      "epoch : 512.0, loss = 0.011465\n",
      "epoch : 513.0, loss = 0.011756\n",
      "epoch : 514.0, loss = 0.011583\n",
      "epoch : 515.0, loss = 0.011683\n",
      "epoch : 516.0, loss = 0.011679\n",
      "epoch : 517.0, loss = 0.011469\n",
      "epoch : 518.0, loss = 0.011519\n",
      "epoch : 519.0, loss = 0.011559\n",
      "epoch : 520.0, loss = 0.011519\n",
      "epoch : 521.0, loss = 0.011377\n",
      "epoch : 522.0, loss = 0.011460\n",
      "epoch : 523.0, loss = 0.011331\n",
      "epoch : 524.0, loss = 0.011742\n",
      "epoch : 525.0, loss = 0.011639\n",
      "epoch : 526.0, loss = 0.011670\n",
      "epoch : 527.0, loss = 0.011626\n",
      "epoch : 528.0, loss = 0.011513\n",
      "epoch : 529.0, loss = 0.011497\n",
      "epoch : 530.0, loss = 0.011407\n",
      "epoch : 531.0, loss = 0.011578\n",
      "epoch : 532.0, loss = 0.011880\n",
      "epoch : 533.0, loss = 0.011664\n",
      "epoch : 534.0, loss = 0.011738\n",
      "epoch : 535.0, loss = 0.011546\n",
      "epoch : 536.0, loss = 0.011709\n",
      "epoch : 537.0, loss = 0.011628\n",
      "epoch : 538.0, loss = 0.011478\n",
      "epoch : 539.0, loss = 0.011605\n",
      "epoch : 540.0, loss = 0.011363\n",
      "epoch : 541.0, loss = 0.011586\n",
      "epoch : 542.0, loss = 0.011648\n",
      "epoch : 543.0, loss = 0.011539\n",
      "epoch : 544.0, loss = 0.011731\n",
      "epoch : 545.0, loss = 0.011650\n",
      "epoch : 546.0, loss = 0.011656\n",
      "epoch : 547.0, loss = 0.011697\n",
      "epoch : 548.0, loss = 0.011692\n",
      "epoch : 549.0, loss = 0.011677\n",
      "epoch : 550.0, loss = 0.011460\n",
      "epoch : 551.0, loss = 0.011576\n",
      "epoch : 552.0, loss = 0.011414\n",
      "epoch : 553.0, loss = 0.011536\n",
      "epoch : 554.0, loss = 0.011373\n",
      "epoch : 555.0, loss = 0.011396\n",
      "epoch : 556.0, loss = 0.011521\n",
      "epoch : 557.0, loss = 0.011738\n",
      "epoch : 558.0, loss = 0.011680\n",
      "epoch : 559.0, loss = 0.011720\n",
      "epoch : 560.0, loss = 0.011549\n",
      "epoch : 561.0, loss = 0.011608\n",
      "epoch : 562.0, loss = 0.011454\n",
      "epoch : 563.0, loss = 0.011395\n",
      "epoch : 564.0, loss = 0.011792\n",
      "epoch : 565.0, loss = 0.011531\n",
      "epoch : 566.0, loss = 0.011524\n",
      "epoch : 567.0, loss = 0.011820\n",
      "epoch : 568.0, loss = 0.011519\n",
      "epoch : 569.0, loss = 0.011451\n",
      "epoch : 570.0, loss = 0.011616\n",
      "epoch : 571.0, loss = 0.011667\n",
      "epoch : 572.0, loss = 0.011453\n",
      "epoch : 573.0, loss = 0.011806\n",
      "epoch : 574.0, loss = 0.011666\n",
      "epoch : 575.0, loss = 0.011555\n",
      "epoch : 576.0, loss = 0.011426\n",
      "epoch : 577.0, loss = 0.011623\n",
      "epoch : 578.0, loss = 0.011533\n",
      "epoch : 579.0, loss = 0.011553\n",
      "epoch : 580.0, loss = 0.011631\n",
      "epoch : 581.0, loss = 0.011554\n",
      "epoch : 582.0, loss = 0.011444\n",
      "epoch : 583.0, loss = 0.011959\n",
      "epoch : 584.0, loss = 0.011563\n",
      "epoch : 585.0, loss = 0.011625\n",
      "epoch : 586.0, loss = 0.011618\n",
      "epoch : 587.0, loss = 0.011478\n",
      "epoch : 588.0, loss = 0.011539\n",
      "epoch : 589.0, loss = 0.011555\n",
      "epoch : 590.0, loss = 0.011498\n",
      "epoch : 591.0, loss = 0.011523\n",
      "epoch : 592.0, loss = 0.011402\n",
      "epoch : 593.0, loss = 0.011670\n",
      "epoch : 594.0, loss = 0.011480\n",
      "epoch : 595.0, loss = 0.011650\n",
      "epoch : 596.0, loss = 0.011627\n",
      "epoch : 597.0, loss = 0.011741\n",
      "epoch : 598.0, loss = 0.011650\n",
      "epoch : 599.0, loss = 0.011673\n",
      "epoch : 600.0, loss = 0.011637\n",
      "epoch : 601.0, loss = 0.011772\n",
      "epoch : 602.0, loss = 0.011677\n",
      "epoch : 603.0, loss = 0.011539\n",
      "epoch : 604.0, loss = 0.011671\n",
      "epoch : 605.0, loss = 0.011624\n",
      "epoch : 606.0, loss = 0.011562\n",
      "epoch : 607.0, loss = 0.011517\n",
      "epoch : 608.0, loss = 0.011707\n",
      "epoch : 609.0, loss = 0.011777\n",
      "epoch : 610.0, loss = 0.011582\n",
      "epoch : 611.0, loss = 0.011653\n",
      "epoch : 612.0, loss = 0.011815\n",
      "epoch : 613.0, loss = 0.011741\n",
      "epoch : 614.0, loss = 0.011699\n",
      "epoch : 615.0, loss = 0.011423\n",
      "epoch : 616.0, loss = 0.011668\n",
      "epoch : 617.0, loss = 0.011555\n",
      "epoch : 618.0, loss = 0.011549\n",
      "epoch : 619.0, loss = 0.011726\n",
      "epoch : 620.0, loss = 0.011529\n",
      "epoch : 621.0, loss = 0.011472\n",
      "epoch : 622.0, loss = 0.011809\n",
      "epoch : 623.0, loss = 0.011571\n",
      "epoch : 624.0, loss = 0.011756\n",
      "epoch : 625.0, loss = 0.011686\n",
      "epoch : 626.0, loss = 0.011762\n",
      "epoch : 627.0, loss = 0.011780\n",
      "epoch : 628.0, loss = 0.011572\n",
      "epoch : 629.0, loss = 0.011493\n",
      "epoch : 630.0, loss = 0.011772\n",
      "epoch : 631.0, loss = 0.011571\n",
      "epoch : 632.0, loss = 0.011470\n",
      "epoch : 633.0, loss = 0.011726\n",
      "epoch : 634.0, loss = 0.011699\n",
      "epoch : 635.0, loss = 0.011733\n",
      "epoch : 636.0, loss = 0.011651\n",
      "epoch : 637.0, loss = 0.011746\n",
      "epoch : 638.0, loss = 0.011679\n",
      "epoch : 639.0, loss = 0.011691\n",
      "epoch : 640.0, loss = 0.011702\n",
      "epoch : 641.0, loss = 0.011771\n",
      "epoch : 642.0, loss = 0.011581\n",
      "epoch : 643.0, loss = 0.011939\n",
      "epoch : 644.0, loss = 0.011408\n",
      "epoch : 645.0, loss = 0.011701\n",
      "epoch : 646.0, loss = 0.011506\n",
      "epoch : 647.0, loss = 0.011553\n",
      "epoch : 648.0, loss = 0.011555\n",
      "epoch : 649.0, loss = 0.011395\n",
      "epoch : 650.0, loss = 0.011627\n",
      "epoch : 651.0, loss = 0.011703\n",
      "epoch : 652.0, loss = 0.011710\n",
      "epoch : 653.0, loss = 0.011696\n",
      "epoch : 654.0, loss = 0.011622\n",
      "epoch : 655.0, loss = 0.011560\n",
      "epoch : 656.0, loss = 0.011565\n",
      "epoch : 657.0, loss = 0.011429\n",
      "epoch : 658.0, loss = 0.011426\n",
      "epoch : 659.0, loss = 0.011777\n",
      "epoch : 660.0, loss = 0.011457\n",
      "epoch : 661.0, loss = 0.011596\n",
      "epoch : 662.0, loss = 0.011678\n",
      "epoch : 663.0, loss = 0.011548\n",
      "epoch : 664.0, loss = 0.011521\n",
      "epoch : 665.0, loss = 0.011408\n",
      "epoch : 666.0, loss = 0.011384\n",
      "epoch : 667.0, loss = 0.011860\n",
      "epoch : 668.0, loss = 0.011827\n",
      "epoch : 669.0, loss = 0.011643\n",
      "epoch : 670.0, loss = 0.011633\n",
      "epoch : 671.0, loss = 0.011957\n",
      "epoch : 672.0, loss = 0.011659\n",
      "epoch : 673.0, loss = 0.011513\n",
      "epoch : 674.0, loss = 0.011505\n",
      "epoch : 675.0, loss = 0.011472\n",
      "epoch : 676.0, loss = 0.011787\n",
      "epoch : 677.0, loss = 0.011482\n",
      "epoch : 678.0, loss = 0.011549\n",
      "epoch : 679.0, loss = 0.011720\n",
      "epoch : 680.0, loss = 0.011581\n",
      "epoch : 681.0, loss = 0.011456\n",
      "epoch : 682.0, loss = 0.011607\n",
      "epoch : 683.0, loss = 0.011552\n",
      "epoch : 684.0, loss = 0.011485\n",
      "epoch : 685.0, loss = 0.011645\n",
      "epoch : 686.0, loss = 0.011749\n",
      "epoch : 687.0, loss = 0.011474\n",
      "epoch : 688.0, loss = 0.011583\n",
      "epoch : 689.0, loss = 0.011789\n",
      "epoch : 690.0, loss = 0.011528\n",
      "epoch : 691.0, loss = 0.011793\n",
      "epoch : 692.0, loss = 0.011772\n",
      "epoch : 693.0, loss = 0.011798\n",
      "epoch : 694.0, loss = 0.011616\n",
      "epoch : 695.0, loss = 0.011678\n",
      "epoch : 696.0, loss = 0.011801\n",
      "epoch : 697.0, loss = 0.011703\n",
      "epoch : 698.0, loss = 0.011696\n",
      "epoch : 699.0, loss = 0.011852\n",
      "epoch : 700.0, loss = 0.011677\n",
      "epoch : 701.0, loss = 0.011389\n",
      "epoch : 702.0, loss = 0.011535\n",
      "epoch : 703.0, loss = 0.011543\n",
      "epoch : 704.0, loss = 0.011658\n",
      "epoch : 705.0, loss = 0.011537\n",
      "epoch : 706.0, loss = 0.011624\n",
      "epoch : 707.0, loss = 0.011685\n",
      "epoch : 708.0, loss = 0.011754\n",
      "epoch : 709.0, loss = 0.011641\n",
      "epoch : 710.0, loss = 0.011668\n",
      "epoch : 711.0, loss = 0.011718\n",
      "epoch : 712.0, loss = 0.011853\n",
      "epoch : 713.0, loss = 0.011449\n",
      "epoch : 714.0, loss = 0.011394\n",
      "epoch : 715.0, loss = 0.011677\n",
      "epoch : 716.0, loss = 0.011555\n",
      "epoch : 717.0, loss = 0.011377\n",
      "epoch : 718.0, loss = 0.011689\n",
      "epoch : 719.0, loss = 0.011586\n",
      "epoch : 720.0, loss = 0.011599\n",
      "epoch : 721.0, loss = 0.011641\n",
      "epoch : 722.0, loss = 0.011602\n",
      "epoch : 723.0, loss = 0.011485\n",
      "epoch : 724.0, loss = 0.011675\n",
      "epoch : 725.0, loss = 0.011485\n",
      "epoch : 726.0, loss = 0.011747\n",
      "epoch : 727.0, loss = 0.011499\n",
      "epoch : 728.0, loss = 0.011452\n",
      "epoch : 729.0, loss = 0.011704\n",
      "epoch : 730.0, loss = 0.011466\n",
      "epoch : 731.0, loss = 0.011410\n",
      "epoch : 732.0, loss = 0.011479\n",
      "epoch : 733.0, loss = 0.011576\n",
      "epoch : 734.0, loss = 0.011557\n",
      "epoch : 735.0, loss = 0.011852\n",
      "epoch : 736.0, loss = 0.011729\n",
      "epoch : 737.0, loss = 0.011764\n",
      "epoch : 738.0, loss = 0.011824\n",
      "epoch : 739.0, loss = 0.011447\n",
      "epoch : 740.0, loss = 0.011618\n",
      "epoch : 741.0, loss = 0.011578\n",
      "epoch : 742.0, loss = 0.011695\n",
      "epoch : 743.0, loss = 0.011383\n",
      "epoch : 744.0, loss = 0.011499\n",
      "epoch : 745.0, loss = 0.011496\n",
      "epoch : 746.0, loss = 0.011661\n",
      "epoch : 747.0, loss = 0.011491\n",
      "epoch : 748.0, loss = 0.011838\n",
      "epoch : 749.0, loss = 0.011611\n",
      "epoch : 750.0, loss = 0.011675\n",
      "epoch : 751.0, loss = 0.011645\n",
      "epoch : 752.0, loss = 0.011823\n",
      "epoch : 753.0, loss = 0.011732\n",
      "epoch : 754.0, loss = 0.011674\n",
      "epoch : 755.0, loss = 0.011540\n",
      "epoch : 756.0, loss = 0.011599\n",
      "epoch : 757.0, loss = 0.011608\n",
      "epoch : 758.0, loss = 0.011589\n",
      "epoch : 759.0, loss = 0.011741\n",
      "epoch : 760.0, loss = 0.011457\n",
      "epoch : 761.0, loss = 0.011550\n",
      "epoch : 762.0, loss = 0.011741\n",
      "epoch : 763.0, loss = 0.011796\n",
      "epoch : 764.0, loss = 0.011580\n",
      "epoch : 765.0, loss = 0.011641\n",
      "epoch : 766.0, loss = 0.011822\n",
      "epoch : 767.0, loss = 0.011725\n",
      "epoch : 768.0, loss = 0.011760\n",
      "epoch : 769.0, loss = 0.011762\n",
      "epoch : 770.0, loss = 0.011534\n",
      "epoch : 771.0, loss = 0.011553\n",
      "epoch : 772.0, loss = 0.011635\n",
      "epoch : 773.0, loss = 0.011584\n",
      "epoch : 774.0, loss = 0.011657\n",
      "epoch : 775.0, loss = 0.011497\n",
      "epoch : 776.0, loss = 0.011791\n",
      "epoch : 777.0, loss = 0.011638\n",
      "epoch : 778.0, loss = 0.011803\n",
      "epoch : 779.0, loss = 0.011362\n",
      "epoch : 780.0, loss = 0.011520\n",
      "epoch : 781.0, loss = 0.011409\n",
      "epoch : 782.0, loss = 0.011681\n",
      "epoch : 783.0, loss = 0.011693\n",
      "epoch : 784.0, loss = 0.011558\n",
      "epoch : 785.0, loss = 0.011608\n",
      "epoch : 786.0, loss = 0.011826\n",
      "epoch : 787.0, loss = 0.011714\n",
      "epoch : 788.0, loss = 0.011546\n",
      "epoch : 789.0, loss = 0.011530\n",
      "epoch : 790.0, loss = 0.011787\n",
      "epoch : 791.0, loss = 0.011377\n",
      "epoch : 792.0, loss = 0.011733\n",
      "epoch : 793.0, loss = 0.011277\n",
      "epoch : 794.0, loss = 0.011400\n",
      "epoch : 795.0, loss = 0.011762\n",
      "epoch : 796.0, loss = 0.011401\n",
      "epoch : 797.0, loss = 0.011559\n",
      "epoch : 798.0, loss = 0.011658\n",
      "epoch : 799.0, loss = 0.011827\n",
      "epoch : 800.0, loss = 0.011875\n",
      "epoch : 801.0, loss = 0.011636\n",
      "epoch : 802.0, loss = 0.011415\n",
      "epoch : 803.0, loss = 0.011440\n",
      "epoch : 804.0, loss = 0.011560\n",
      "epoch : 805.0, loss = 0.011660\n",
      "epoch : 806.0, loss = 0.011506\n",
      "epoch : 807.0, loss = 0.011785\n",
      "epoch : 808.0, loss = 0.011516\n",
      "epoch : 809.0, loss = 0.011411\n",
      "epoch : 810.0, loss = 0.011694\n",
      "epoch : 811.0, loss = 0.011577\n",
      "epoch : 812.0, loss = 0.011420\n",
      "epoch : 813.0, loss = 0.011637\n",
      "epoch : 814.0, loss = 0.011704\n",
      "epoch : 815.0, loss = 0.011554\n",
      "epoch : 816.0, loss = 0.011642\n",
      "epoch : 817.0, loss = 0.011592\n",
      "epoch : 818.0, loss = 0.011842\n",
      "epoch : 819.0, loss = 0.011602\n",
      "epoch : 820.0, loss = 0.011489\n",
      "epoch : 821.0, loss = 0.011696\n",
      "epoch : 822.0, loss = 0.011263\n",
      "epoch : 823.0, loss = 0.011546\n",
      "epoch : 824.0, loss = 0.011627\n",
      "epoch : 825.0, loss = 0.011811\n",
      "epoch : 826.0, loss = 0.011495\n",
      "epoch : 827.0, loss = 0.011639\n",
      "epoch : 828.0, loss = 0.011745\n",
      "epoch : 829.0, loss = 0.011464\n",
      "epoch : 830.0, loss = 0.011586\n",
      "epoch : 831.0, loss = 0.011680\n",
      "epoch : 832.0, loss = 0.011700\n",
      "epoch : 833.0, loss = 0.011376\n",
      "epoch : 834.0, loss = 0.011648\n",
      "epoch : 835.0, loss = 0.011692\n",
      "epoch : 836.0, loss = 0.011389\n",
      "epoch : 837.0, loss = 0.011477\n",
      "epoch : 838.0, loss = 0.011630\n",
      "epoch : 839.0, loss = 0.011567\n",
      "epoch : 840.0, loss = 0.011431\n",
      "epoch : 841.0, loss = 0.011634\n",
      "epoch : 842.0, loss = 0.011523\n",
      "epoch : 843.0, loss = 0.011697\n",
      "epoch : 844.0, loss = 0.011619\n",
      "epoch : 845.0, loss = 0.011630\n",
      "epoch : 846.0, loss = 0.011880\n",
      "epoch : 847.0, loss = 0.011589\n",
      "epoch : 848.0, loss = 0.011603\n",
      "epoch : 849.0, loss = 0.011615\n",
      "epoch : 850.0, loss = 0.011459\n",
      "epoch : 851.0, loss = 0.011400\n",
      "epoch : 852.0, loss = 0.011622\n",
      "epoch : 853.0, loss = 0.011509\n",
      "epoch : 854.0, loss = 0.011507\n",
      "epoch : 855.0, loss = 0.011662\n",
      "epoch : 856.0, loss = 0.011669\n",
      "epoch : 857.0, loss = 0.011636\n",
      "epoch : 858.0, loss = 0.011417\n",
      "epoch : 859.0, loss = 0.011550\n",
      "epoch : 860.0, loss = 0.011708\n",
      "epoch : 861.0, loss = 0.011762\n",
      "epoch : 862.0, loss = 0.011581\n",
      "epoch : 863.0, loss = 0.011487\n",
      "epoch : 864.0, loss = 0.011669\n",
      "epoch : 865.0, loss = 0.011680\n",
      "epoch : 866.0, loss = 0.011411\n",
      "epoch : 867.0, loss = 0.011455\n",
      "epoch : 868.0, loss = 0.011548\n",
      "epoch : 869.0, loss = 0.011571\n",
      "epoch : 870.0, loss = 0.011406\n",
      "epoch : 871.0, loss = 0.011641\n",
      "epoch : 872.0, loss = 0.011747\n",
      "epoch : 873.0, loss = 0.011663\n",
      "epoch : 874.0, loss = 0.011674\n",
      "epoch : 875.0, loss = 0.011507\n",
      "epoch : 876.0, loss = 0.011606\n",
      "epoch : 877.0, loss = 0.011496\n",
      "epoch : 878.0, loss = 0.011757\n",
      "epoch : 879.0, loss = 0.011489\n",
      "epoch : 880.0, loss = 0.011606\n",
      "epoch : 881.0, loss = 0.011630\n",
      "epoch : 882.0, loss = 0.011530\n",
      "epoch : 883.0, loss = 0.011372\n",
      "epoch : 884.0, loss = 0.011543\n",
      "epoch : 885.0, loss = 0.011430\n",
      "epoch : 886.0, loss = 0.011508\n",
      "epoch : 887.0, loss = 0.011640\n",
      "epoch : 888.0, loss = 0.011615\n",
      "epoch : 889.0, loss = 0.011528\n",
      "epoch : 890.0, loss = 0.011458\n",
      "epoch : 891.0, loss = 0.011735\n",
      "epoch : 892.0, loss = 0.011710\n",
      "epoch : 893.0, loss = 0.011653\n",
      "epoch : 894.0, loss = 0.011591\n",
      "epoch : 895.0, loss = 0.011678\n",
      "epoch : 896.0, loss = 0.011584\n",
      "epoch : 897.0, loss = 0.011657\n",
      "epoch : 898.0, loss = 0.011824\n",
      "epoch : 899.0, loss = 0.011429\n",
      "epoch : 900.0, loss = 0.011513\n",
      "epoch : 901.0, loss = 0.011347\n",
      "epoch : 902.0, loss = 0.011566\n",
      "epoch : 903.0, loss = 0.011505\n",
      "epoch : 904.0, loss = 0.011760\n",
      "epoch : 905.0, loss = 0.011719\n",
      "epoch : 906.0, loss = 0.011562\n",
      "epoch : 907.0, loss = 0.011725\n",
      "epoch : 908.0, loss = 0.011535\n",
      "epoch : 909.0, loss = 0.011656\n",
      "epoch : 910.0, loss = 0.011395\n",
      "epoch : 911.0, loss = 0.011735\n",
      "epoch : 912.0, loss = 0.011613\n",
      "epoch : 913.0, loss = 0.011664\n",
      "epoch : 914.0, loss = 0.011814\n",
      "epoch : 915.0, loss = 0.011682\n",
      "epoch : 916.0, loss = 0.011573\n",
      "epoch : 917.0, loss = 0.011566\n",
      "epoch : 918.0, loss = 0.011552\n",
      "epoch : 919.0, loss = 0.011744\n",
      "epoch : 920.0, loss = 0.011366\n",
      "epoch : 921.0, loss = 0.011647\n",
      "epoch : 922.0, loss = 0.011491\n",
      "epoch : 923.0, loss = 0.011562\n",
      "epoch : 924.0, loss = 0.011722\n",
      "epoch : 925.0, loss = 0.011682\n",
      "epoch : 926.0, loss = 0.011730\n",
      "epoch : 927.0, loss = 0.011467\n",
      "epoch : 928.0, loss = 0.011614\n",
      "epoch : 929.0, loss = 0.011463\n",
      "epoch : 930.0, loss = 0.011805\n",
      "epoch : 931.0, loss = 0.011556\n",
      "epoch : 932.0, loss = 0.011556\n",
      "epoch : 933.0, loss = 0.011530\n",
      "epoch : 934.0, loss = 0.011762\n",
      "epoch : 935.0, loss = 0.011807\n",
      "epoch : 936.0, loss = 0.011518\n",
      "epoch : 937.0, loss = 0.011428\n",
      "epoch : 938.0, loss = 0.011745\n",
      "epoch : 939.0, loss = 0.011419\n",
      "epoch : 940.0, loss = 0.011559\n",
      "epoch : 941.0, loss = 0.011535\n",
      "epoch : 942.0, loss = 0.011928\n",
      "epoch : 943.0, loss = 0.011548\n",
      "epoch : 944.0, loss = 0.011730\n",
      "epoch : 945.0, loss = 0.011523\n",
      "epoch : 946.0, loss = 0.011530\n",
      "epoch : 947.0, loss = 0.011518\n",
      "epoch : 948.0, loss = 0.011704\n",
      "epoch : 949.0, loss = 0.011741\n",
      "epoch : 950.0, loss = 0.011634\n",
      "epoch : 951.0, loss = 0.011508\n",
      "epoch : 952.0, loss = 0.011662\n",
      "epoch : 953.0, loss = 0.011805\n",
      "epoch : 954.0, loss = 0.011751\n",
      "epoch : 955.0, loss = 0.011702\n",
      "epoch : 956.0, loss = 0.011631\n",
      "epoch : 957.0, loss = 0.011715\n",
      "epoch : 958.0, loss = 0.011682\n",
      "epoch : 959.0, loss = 0.011465\n",
      "epoch : 960.0, loss = 0.011449\n",
      "epoch : 961.0, loss = 0.011670\n",
      "epoch : 962.0, loss = 0.011594\n",
      "epoch : 963.0, loss = 0.011605\n",
      "epoch : 964.0, loss = 0.011573\n",
      "epoch : 965.0, loss = 0.011665\n",
      "epoch : 966.0, loss = 0.011779\n",
      "epoch : 967.0, loss = 0.011621\n",
      "epoch : 968.0, loss = 0.011857\n",
      "epoch : 969.0, loss = 0.011562\n",
      "epoch : 970.0, loss = 0.011744\n",
      "epoch : 971.0, loss = 0.011632\n",
      "epoch : 972.0, loss = 0.011615\n",
      "epoch : 973.0, loss = 0.011726\n",
      "epoch : 974.0, loss = 0.011632\n",
      "epoch : 975.0, loss = 0.011460\n",
      "epoch : 976.0, loss = 0.011832\n",
      "epoch : 977.0, loss = 0.011515\n",
      "epoch : 978.0, loss = 0.011638\n",
      "epoch : 979.0, loss = 0.011672\n",
      "epoch : 980.0, loss = 0.011530\n",
      "epoch : 981.0, loss = 0.011504\n",
      "epoch : 982.0, loss = 0.011400\n",
      "epoch : 983.0, loss = 0.011488\n",
      "epoch : 984.0, loss = 0.011518\n",
      "epoch : 985.0, loss = 0.011458\n",
      "epoch : 986.0, loss = 0.011415\n",
      "epoch : 987.0, loss = 0.011598\n",
      "epoch : 988.0, loss = 0.011539\n",
      "epoch : 989.0, loss = 0.011511\n",
      "epoch : 990.0, loss = 0.011477\n",
      "epoch : 991.0, loss = 0.011336\n",
      "epoch : 992.0, loss = 0.011683\n",
      "epoch : 993.0, loss = 0.011484\n",
      "epoch : 994.0, loss = 0.011639\n",
      "epoch : 995.0, loss = 0.011733\n",
      "epoch : 996.0, loss = 0.011839\n",
      "epoch : 997.0, loss = 0.011659\n",
      "epoch : 998.0, loss = 0.011707\n",
      "epoch : 999.0, loss = 0.011745\n",
      "epoch : 1000.0, loss = 0.011385\n",
      "epoch : 1001.0, loss = 0.011493\n"
     ]
    }
   ],
   "source": [
    "best_state_dict = train_autoencoder(10, batch_maker, optimizer, net, criterion,max_epochs=10000)\n",
    "#net.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(wd_path, \"models\")\n",
    "\n",
    "net.save_model(os.path.join(models_path, \"ae10_0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "batch_maker = get_tile_batch(image_path_list,batch_size=1)\n",
    "images = next(batch_maker)\n",
    "\n",
    "images = images.to(device)\n",
    "x_r = net.encode(images[0].view(3*8*8))\n",
    "x_rebuilt_r = net.decode(x_r).detach().cpu().view(3,8,8)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(x_rebuilt_r))\n",
    "print(\"Original\")\n",
    "imshow(images[0].detach().cpu().view(3,8,8))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (activation): ReLU()\n",
       "  (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
       "  (fc2): Linear(in_features=96, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=96, bias=True)\n",
       "  (fc4): Linear(in_features=96, out_features=192, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = os.path.join(wd_path, \"models\")\n",
    "loaded_autoencoder = AutoEncoder.load_autoencoder(os.path.join(models_path, \"ae_0.pt\"))\n",
    "loaded_autoencoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Reconstructed\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEOUlEQVR4nO3dvVKbVxRA0SuERBznVTMTP1uKzOSV8uMIGwwCpBRuZVXJ8S7WKqE495O0dWcoOJvz+byAnpvvfQDgMnFClDghSpwQJU6Iur32yw8//zL2p9z373+aGrV+fPdubNZaa21vtmOzDofD2Ky//vxjbNY/Hz+OzVprrccvj2Ozfv39t82ln7s5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEHV1HcPx6WnqHKMrC242F//7/f9mM/hsz8/HsVkPDw9jsz4PzlprrU8Pn0fnXeLmhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTVdQwPj49T51hrcEXCZjP7nXR6O43NOhwOY7PuP82tLPh78LnWWuvL4+z6h0vcnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Rd3ZXy/PQ0dY51Pp/HZr0N7i75am4PzP395K6UuVmfB2ettdbx+DI67xI3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6KurmM4nefWFpxOk+sY3sZmfZ039zoeX45js56en8dmvb6+js1aa62XwdfxW9ycECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiLq6juH2djd1jrW73Y7N2u/nnmuttV5e59Y/7Aafbb+bm3Wznft8rLXWdnjeJW5OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRF1dx7Ab/Hf7+7sfxmbt9vuxWWutdbOdW8dwd3c3Nms/OWv4PTu9zb1n3+LmhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IerqrpTb2+3UOdZ28Gti/BvpZjM2ajv4Qu53Vz8+/6m7/dzenrXWOp9Oo/MucXNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanM+n7/3GYAL3JwQJU6IEidEiROixAlR4oSofwFA8G57pz7TMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEy0lEQVR4nO3dsWudZRjG4efYhKYWBVGERpvUKjXZKlIntw4dHCqhiCC4qEtRcHFycdHWlFa3ri7+AzqJCGkH0ZK0BUNRB1FETUvUGKUlxPb4D5yeSZ7ehesazzfcHwd+54WzvIPhcFhAnnvu9AsAo4kTQokTQokTQokTQk2Me/jsk8+0/ZW7eOpk11Tt3DHZtlVVVbe226ZeWDjatnVp5ULb1vrab21bVVVvvvF629Yn310ZjPrcyQmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhxAmhBuMuz9374EzbdQxbN653TdX83FzbVlXVi8cW2rZubvV9j7smd7RtnVl8v22rqmr3vVNtWxfW1lzHAHcTcUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUKoiXEPP/1yqek1qnZOTbZtfXjqdNtWVdXxt99q25qfe6Jta/rhh9q21murbauq6trmP617ozg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTYu1IOH32u6z3qjz/X27ZqY7Nvq6re+WCxbevc55+1bR1beL5t6+Lq5batqqrDR4607o3i5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQg+FweNuHH59fuv3D/9n+/fu6pury8krbVlXV6RPvtW29+vJLbVuLJ95t2zowO9u2VVW1snypbWt7azgY9bmTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KNvY5hcnam7TqGfzc3uqZqemZf21ZV1fHXXmnb+ur8UtvW6sXltq3fr11t26qqmpne07a1+u1PrmOAu4k4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTEuIdff3Gu6z3qgfvva9u6+vMvbVtVVTf+/qtt69Fdu9u2fv3mStvW9COPtW1VVd26ud26N4qTE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KNvSvl6QPzXe9RNdH3O/H43tm2raqqH3/4vm3ro7Nn27amGn/br29stG1VVR166mDr3ihOTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgg1GA6Hd/odgBGcnBBKnBBKnBBKnBBKnBBKnBDqP4Z5e95b1xafAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "batch_maker = get_tile_batch([os.path.join(wd_path, \"images\",\"val_0_0.jpeg\")],batch_size=1)\n",
    "images = next(batch_maker)\n",
    "images = images.to(device)\n",
    "\n",
    "print(\"Original\")\n",
    "\n",
    "x_r = loaded_autoencoder.encode(images.view(-1,3*8*8))\n",
    "x_rebuilt_r = loaded_autoencoder.decode(x_r).detach().cpu().view(3,8,8)\n",
    "\n",
    "print(\"Reconstructed\")\n",
    "# show images\n",
    "imshow(x_rebuilt_r)\n",
    "print(\"Original\")\n",
    "\n",
    "imshow(images[0].detach().cpu().view(3,8,8))\n",
    "# print labels"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80eecae6fe367bf31bafaafee0935a4935edb539e731c9082f4e2c31e5b4f550"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
